{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RA, DE for DC2 Run 2.2i DR6 Object Table\n",
    "### Michael Wood-Vasey (@wmwv)\n",
    "### Last Verified to Run: 2021-05-14 by MWV\n",
    "\n",
    "Inspect the Run 2.2i DR6d RA, Dec distribution \n",
    "\n",
    "#### Run 2.2i DR6d as of 2020-08-12 includes  \n",
    "  * 166 tracts\n",
    "\n",
    "\n",
    "Logistics:\n",
    "\n",
    "1. These tests were conducted on NERSC through the https://jupyter.nersc.gov interface.  \n",
    "Note: To enable re-rastering when zooming, use the JupyterLab Classic interface.\n",
    "You can launch this from an active JupyterHub Notebook by selecting \"Help->Launch Classic Notebook\".\n",
    "  * Assuming that you are currently reading this Notebook in JupyterHub and have an active kernel.\n",
    "  * You can select the \"Running\" tab and then select the Notebook you want.\n",
    "  * You could instead browse through the full filesystem path under the \"Files\" tab to find your Notebook, but that's a lot more clicking.  You may want to take this aproach to launch some other Notebook that's not currently running under JupyterHub.\n",
    "\n",
    "2. Requires:\n",
    "```\n",
    "holoviews\n",
    "datashader\n",
    "bokeh\n",
    "pyarrow >= 0.13.1\n",
    "```\n",
    "\n",
    "Up-to-date versions of each of these are available in `desc-python-bleed` kernel\n",
    "\n",
    "3. This was run using the `desc-python-bleed` kernel\n",
    "\n",
    "We directly use the DPDD Parquet files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Needed Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import astropy.units as u\n",
    "import healpy as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorcet\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "\n",
    "from bokeh.models import HoverTool\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import datashader as ds\n",
    "import holoviews as hv\n",
    "from holoviews.operation import histogram\n",
    "from holoviews.operation.datashader import datashade, shade, dynspread, rasterize\n",
    "from holoviews.plotting.util import process_cmap\n",
    "from holoviews.streams import RangeXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = 'viridis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start our Dask Cluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're only going to load the RA, Dec, so we don't need that much memory for the final product.\n",
    "There's a 42 GB limit on memory directly in the JupyterHub environment, which we will suceed in staying under.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a local Dask Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_parquet(\"dc2_run2.2i_dr6c_ra_dec.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_data_dir = f\"/global/cfs/cdirs/lsst/shared/DC2-prod/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_release = \"dr6\"\n",
    "\n",
    "run_data_dir = f\"Run2.2i/dpdd/Run2.2i-{data_release}/object_dpdd_only\"\n",
    "data_path = os.path.join(desc_data_dir, run_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['ra', 'dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_parquet(data_path, columns=columns, engine='pyarrow', kwargs={'dataset': {'use_legacy_dataset': False}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Density in RA, Dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DC2 Run 2.x WFD and DDF regions\n",
    "https://docs.google.com/document/d/18nNVImxGioQ3tcLFMRr67G_jpOzCIOdar9bjqChueQg/view\n",
    "https://github.com/LSSTDESC/DC2_visitList/blob/master/DC2visitGen/notebooks/DC2_Run2_regionCoords_WFD.ipynb\n",
    "\n",
    "| Location          | RA (degrees) | Dec (degrees) | RA (degrees) | Dec (degrees) |\n",
    "|:----------------- |:------------ |:------------- |:------------ |:------------- |\n",
    "| Region            | WFD          | WFD           | DDF          | DDF           |\n",
    "| Center            | 61.856114    | -35.79        | 53.125       | -28.100       |\n",
    "| North-East Corner | 71.462228    | -27.25        | 53.764       | -27.533       |\n",
    "| North-West Corner | 52.250000    | -27.25        | 52.486       | -27.533       |\n",
    "| South-West Corner | 49.917517    | -44.33        | 52.479       | -28.667       |\n",
    "| South-East Corner | 73.794710    | -44.33        | 53.771       | -28.667       |\n",
    "\n",
    "(Note that the order of the rows above is different than in the DC2 papers.  The order of the rows above goes around the perimeter in order.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc2_run2x_wfd = [[71.462228, -27.25], [52.250000, -27.25], [49.917517, -44.33], [73.794710, -44.33]]\n",
    "dc2_run2x_ddf = [[53.764, -27.533], [52.486, -27.533], [52.479, -28.667], [53.771, -28.667]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc2_run2x_wfd_df = pd.DataFrame({'ra': [coord[0] for coord in dc2_run2x_wfd] + [dc2_run2x_wfd[0][0]],\n",
    "                                 'dec': [coord[1] for coord in dc2_run2x_wfd] + [dc2_run2x_wfd[0][1]]})\n",
    "dc2_run2x_ddf_df = pd.DataFrame({'ra': [coord[0] for coord in dc2_run2x_ddf] + [dc2_run2x_ddf[0][0]],\n",
    "                                 'dec': [coord[1] for coord in dc2_run2x_ddf] + [dc2_run2x_ddf[0][1]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_dc2_region(ra_dec, dc2_run2x_wfd_df=dc2_run2x_wfd_df, dc2_run2x_ddf_df=dc2_run2x_ddf_df):\n",
    "    # This region isn't quite a polygon.  The sides should be curved.\n",
    "    wfd_region = hv.Path(dc2_run2x_wfd_df).opts(color='red')\n",
    "    ddf_region = hv.Path(dc2_run2x_ddf_df).opts(color='orange')\n",
    "    ra_dec = ra_dec * wfd_region * ddf_region\n",
    "\n",
    "    max_delta_ra = dc2_run2x_wfd_df['ra'][3] - dc2_run2x_wfd_df['ra'][2]\n",
    "    delta_dec = dc2_run2x_wfd_df['dec'][1] - dc2_run2x_wfd_df['dec'][3]\n",
    "    grow_buffer = 0.05\n",
    "\n",
    "    # Notice that these are specified in increasing RA left->right\n",
    "    # We rely on the invert_xaxis True above to flip this in the display\n",
    "    # It's important to get this right because these ranges are used for data selection\n",
    "    # and then the range is flipped in the display.\n",
    "    ra_dec.opts(xlim=(dc2_run2x_wfd_df['ra'][2] - max_delta_ra * grow_buffer,\n",
    "                dc2_run2x_wfd_df['ra'][3] + max_delta_ra * grow_buffer))\n",
    "    ra_dec.opts(ylim=(dc2_run2x_wfd_df['dec'][3] - delta_dec * grow_buffer,\n",
    "                dc2_run2x_wfd_df['dec'][1] + delta_dec * grow_buffer))\n",
    "\n",
    "    return ra_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_dc2_region_ddf(ra_dec, dc2_run2x_wfd_df=dc2_run2x_wfd_df, dc2_run2x_ddf_df=dc2_run2x_ddf_df):\n",
    "    # This region isn't quite a polygon.  The sides should be curved.\n",
    "    ddf_region = hv.Path(dc2_run2x_ddf_df).opts(color='orange')\n",
    "    ra_dec = ra_dec * ddf_region\n",
    "\n",
    "    max_delta_ra = dc2_run2x_wfd_df['ra'][3] - dc2_run2x_wfd_df['ra'][2]\n",
    "    delta_dec = dc2_run2x_wfd_df['dec'][1] - dc2_run2x_wfd_df['dec'][3]\n",
    "    grow_buffer = 0.05\n",
    "\n",
    "    # Notice that these are specified in increasing RA left->right\n",
    "    # We rely on the invert_xaxis True above to flip this in the display\n",
    "    # It's important to get this right because these ranges are used for data selection\n",
    "    # and then the range is flipped in the display.\n",
    "    ra_dec.opts(xlim=(dc2_run2x_wfd_df['ra'][2] - max_delta_ra * grow_buffer,\n",
    "                dc2_run2x_wfd_df['ra'][3] + max_delta_ra * grow_buffer))\n",
    "    ra_dec.opts(ylim=(dc2_run2x_wfd_df['dec'][3] - delta_dec * grow_buffer,\n",
    "                dc2_run2x_wfd_df['dec'][1] + delta_dec * grow_buffer))\n",
    "\n",
    "    return ra_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ra_dec(df, dc2_run2x_wfd_df=dc2_run2x_wfd_df, dc2_run2x_ddf_df=dc2_run2x_ddf_df,\n",
    "                show_dc2_region=True, cmap=\"bmy\", bins=100, cmin=10):\n",
    "    \"\"\"Show rasterized RA, Dec object density.\n",
    "    \n",
    "    We're just doing this on a rectilinear grid\n",
    "    The distortion is noticeable from the lowest to highest Dec in the change in density due to the change in area.\"\"\"\n",
    "    points_ra_dec = hv.Points(df, kdims=[hv.Dimension('ra', soft_range=(dc2_run2x_wfd[2][0], dc2_run2x_wfd[3][0])),\n",
    "                                         hv.Dimension('dec', soft_range=(dc2_run2x_wfd[3][1], dc2_run2x_wfd[1][1]))])\n",
    "    # We have to define the colormap here now, because the opts aren't passed through the datashade->Points.\n",
    "    # See, e.g., https://github.com/holoviz/holoviews/issues/4125\n",
    "    ra_dec = datashade(points_ra_dec, cmap=process_cmap(cmap, provider=\"colorcet\"), precompute=True)\n",
    "    ra_dec = ra_dec.opts(invert_xaxis=True)  # Flip to East left\n",
    "#    ra_dec = ra_dec.opts(precompute=True)\n",
    "    if show_dc2_region:\n",
    "        ra_dec = overlay_dc2_region(ra_dec, dc2_run2x_wfd_df=dc2_run2x_wfd_df, dc2_run2x_ddf_df=dc2_run2x_ddf_df)\n",
    "   \n",
    "    return ra_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_dec = plot_ra_dec(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_dec.opts(width=800, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For exaples of specifying hover-over tools in Bokeh, see:\n",
    "\n",
    "https://holoviews.org/user_guide/Plotting_with_Bokeh.html\n",
    "\n",
    "https://docs.bokeh.org/en/latest/docs/user_guide/tools.html\n",
    "\n",
    "https://holoviz.org/tutorial/Large_Data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(73.79471 + 49.917517)/2, (-44.33 + -27.25)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc2_run2x_wfd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fake up the axis labels to approximate the RA, Dec values.  Would be nice to put on the curved lines eventually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hv.save(foo, 'DC2_Run2.2i_DR6c_ra_dec.png', fmt='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall object density distribution looks good.\n",
    "\n",
    "Notes:\n",
    "* If you are viewing this through a direct JupyterLab connection (Jupyter Classic Notebook, or separately on your own machine or setup), the plot will re-raster as you zoom in and out.  This functionality is not available within the JupyterHub environment.  JupyterHub doesn't allow the JavaScript callbacks in the browser back to the server that are necessary to do the re-rastering.\n",
    "* We explicitly excluded the tracts that overlap the DDF region (orange square upper-right corner).\n",
    "* There are also a few patches that failed within the main region.\n",
    "* The saved files are significant cropped.  I don't understand what's going on.\n",
    "\n",
    "See the input visit coverage map here:  \n",
    "https://github.com/LSSTDESC/ImageProcessingPipelines/issues/97#issuecomment-498303504\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc2_run2x_wfd_center = [(dc2_run2x_wfd_df['ra'][0] + dc2_run2x_wfd_df['ra'][1])/2,\n",
    "                        (dc2_run2x_wfd_df['dec'][0] + dc2_run2x_wfd_df['dec'][2])/2]                         \n",
    "mollweide = hp.projector.MollweideProj(rot=(dc2_run2x_wfd_center[0], dc2_run2x_wfd_center[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "def make_linear_interpolator(mollweide):\n",
    "    X, Y = mollweide._MollweideProj__molldata\n",
    "    return scipy.interpolate.interp1d(X, Y, bounds_error=False, fill_value=(Y[0], Y[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lininterp = make_linear_interpolator(mollweide)\n",
    "rotmat = mollweide.rotator._matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir2vec from healpy.rotator\n",
    "# Rewritten to work for Dask\n",
    "def dir2vec(theta, phi):\n",
    "    lon, lat = theta, phi\n",
    "    theta, phi = np.pi / 2 - da.radians(lat), da.radians(lon)\n",
    "    ct, st, cp, sp = da.cos(theta), da.sin(theta), da.cos(phi), da.sin(phi)\n",
    "    vx, vy, vz = st * cp, st * sp, ct\n",
    "    return vx, vy, vz\n",
    "\n",
    "def vec2dir(vx, vy, vz):\n",
    "    r = da.sqrt(vx ** 2 + vy ** 2 + vz ** 2)\n",
    "    theta = da.arccos(vz / r)\n",
    "    phi = da.arctan2(vy, vx)\n",
    "    \n",
    "    return theta, phi\n",
    "\n",
    "def vec2xy(vx, vy, vz, mollweide):\n",
    "    rotmat = mollweide.rotator._matrix\n",
    "    vxp, vyp, vzp = da.tensordot(rotmat, da.array([vx, vy, vz]), axes=(1, 0))\n",
    "\n",
    "    theta, phi = vec2dir(vxp, vyp, vzp)\n",
    "        \n",
    "    phi = (phi + np.pi) % (2 * np.pi) - np.pi\n",
    "    lat = (np.pi / 2) - theta\n",
    "    \n",
    "    phi = phi.to_dask_dataframe()\n",
    "    lat = lat.to_dask_dataframe()\n",
    "\n",
    "    # Wrap the result of the SciPy interpolation function as a Dask Array\n",
    "    A = dd.map_partitions(lininterp, lat, meta=('A', 'float64'))\n",
    "    \n",
    "    flip = mollweide._flip\n",
    "\n",
    "    x = flip * (2 / np.pi) * phi * da.cos(A)\n",
    "    y = da.sin(A)\n",
    "\n",
    "    return x, y\n",
    "    \n",
    "def moll_ang2xy(theta, phi, mollweide):\n",
    "    vx, vy, vz = dir2vec(theta, phi)\n",
    "    return vec2xy(vx, vy, vz, mollweide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_in_sides_from_corners(x, y, n=100):\n",
    "    edges_x = []\n",
    "    edges_y = []\n",
    "    for start, end in zip(x[:-1], x[1:]):\n",
    "        edges_x.extend(np.linspace(start, end, n))\n",
    "    for start, end in zip(y[:-1], y[1:]):\n",
    "        edges_y.extend(np.linspace(start, end, n))\n",
    "        \n",
    "    return edges_x, edges_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlay(df, mollweide, color='red', **kwargs):\n",
    "    df['ra'], df['dec']\n",
    "    edges_ra, edges_dec = fill_in_sides_from_corners(df['ra'], df['dec'], **kwargs)\n",
    "    edges_x, edges_y = mollweide.ang2xy(edges_ra, edges_dec, lonlat=True)\n",
    "    \n",
    "    return hv.Path((edges_x, edges_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfd_outline = get_overlay(dc2_run2x_wfd_df, mollweide).opts(color='red')\n",
    "ddf_outline = get_overlay(dc2_run2x_ddf_df, mollweide).opts(color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ra_dec_mollweide(df, dc2_run2x_wfd_df=dc2_run2x_wfd_df, dc2_run2x_ddf_df=dc2_run2x_ddf_df,\n",
    "                          show_dc2_region=True, cmap=\"bmy\", cmin=10,\n",
    "                          also_return_mollweide=False):\n",
    "    \"\"\"Use a Mollweide projection to get equal-area densities in the aggregation.\n",
    "    \n",
    "    also_return_mollweide: [bool]  Return both the holoviews map and the mollweide projection object as a tuple\n",
    "    \"\"\"\n",
    "\n",
    "    dc2_run2x_wfd_center = [(dc2_run2x_wfd_df['ra'][0] + dc2_run2x_wfd_df['ra'][1])/2,\n",
    "                            (dc2_run2x_wfd_df['dec'][0] + dc2_run2x_wfd_df['dec'][2])/2]                         \n",
    "    mollweide = hp.projector.MollweideProj(rot=(dc2_run2x_wfd_center[0], dc2_run2x_wfd_center[1]))\n",
    "    x, y = moll_ang2xy(df['ra'], df['dec'], mollweide=mollweide)\n",
    "    \n",
    "    points_ra_dec = hv.Points((x, y))\n",
    "\n",
    "    # We have to define the colormap here now, because the opts aren't passed through the datashade->Points.\n",
    "    # See, e.g., https://github.com/holoviz/holoviews/issues/4125\n",
    "#    ra_dec = datashade(points_ra_dec, cmap=process_cmap(cmap, provider=\"colorcet\"))\n",
    "    ra_dec = rasterize(points_ra_dec, width=1080, height=1080)\n",
    "    \n",
    "    if also_return_mollweide:\n",
    "        return ra_dec, mollweide\n",
    "    else:\n",
    "        return ra_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ra_dec_moll = plot_ra_dec_mollweide(good, show_dc2_region=False)\n",
    "ra_dec_moll, mollweide = plot_ra_dec_mollweide(df, also_return_mollweide=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ra = 14\n",
    "n_dec = 10\n",
    "major_ticks_ra = np.linspace(74.00, 48.00, n_ra)\n",
    "major_ticks_dec = np.linspace(-45.00, -27.00, n_dec)\n",
    "# If you set the Dec to the be the rotation center you get Delta x steps that are constant\n",
    "left_ra = np.zeros(n_dec) + dc2_run2x_wfd_df['ra'][0]  # It doesn't matter what this is, because it doesn't affect Dec.\n",
    "bottom_dec = np.zeros(n_ra) + dc2_run2x_wfd_df['dec'][2]\n",
    "major_ticks_x, _ = mollweide.ang2xy(major_ticks_ra, bottom_dec, lonlat=True)\n",
    "# RA doesn't matter for Dec\n",
    "_, major_ticks_y = mollweide.ang2xy(left_ra, major_ticks_dec, lonlat=True)\n",
    "\n",
    "major_ticks_and_labels_x = [(x, f\"{ra:0.0f}\") for x, ra in zip(major_ticks_x, major_ticks_ra)]\n",
    "major_ticks_and_labels_y = [(y, f\"{dec:0.0f}\") for y, dec in zip(major_ticks_y, major_ticks_dec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_dec_moll = ra_dec_moll.opts(xlabel='RA', ylabel='Dec', xticks=major_ticks_and_labels_x, yticks=major_ticks_and_labels_y)\n",
    "ra_dec_moll = ra_dec_moll.opts(hv.opts.Image(colorbar=True, clim=(10, None), clipping_colors={'min': 'gray'},\n",
    "                               cmap=process_cmap(\"viridis\", provider=\"matplotlib\")))\n",
    "ra_dec_moll = ra_dec_moll.opts(width=480, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc2_ra_dec_coverage = ra_dec_moll * wfd_outline * ddf_outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc2_ra_dec_coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Area Covered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_area(df, threshold=0.25, nside=1024, verbose=False):\n",
    "    \"\"\"Calculate the area covered by a catalog with 'ra', 'dec'\n",
    "    \n",
    "    Parameters:\n",
    "    --\n",
    "    cat: DataFrame, dict-like with 'ra', 'dec', keys\n",
    "    threshold:  float\n",
    "        Fraction of median value required to count a pixel.\n",
    "    nside:  int\n",
    "        Healpix NSIDE.  NSIDE=1024 is ~12 sq arcmin/pixel, NSIDE=4096 is 0.74 sq. arcmin/pixel\n",
    "        Increasing nside will decrease calculated area as holes become better resolved \n",
    "        and relative Poisson fluctuations in number counts become more significant.\n",
    "    verbose:  bool\n",
    "        Print details on nside, number of significant pixels, and area/pixel.\n",
    "        \n",
    "    Returns:\n",
    "    --\n",
    "    area:  Astropy Quantity.\n",
    "    \"\"\"\n",
    "    import healpy as hp\n",
    "\n",
    "    # MWV: The following line of code makes me sad, but \n",
    "    # We need to make a matching DataFrame for nside to satisfy conservative\n",
    "    # Pandas 1.2.4 requirement that all ufuncs have arguments of the same type.\n",
    "    # `ang2pix` takes `nside`, `ra`, `dec` and so each of those need to be of the same type.\n",
    "    # That means we need to take our simple int nside and convert it to a Series.\n",
    "    # We explicitly base it off the df['ra'] so that the partitions are automatically propagated\n",
    "    # And then set the value with 'nside' and cast to int.\n",
    "    nside_ds = (nside + 0 * df['ra']).astype(int)\n",
    "\n",
    "    indices = hp.ang2pix(nside_ds, df['ra'], df['dec'], lonlat=True)\n",
    "    idx, counts = np.unique(indices, return_counts=True)\n",
    "    \n",
    "    # Take the 25% of the median value of the non-zero counts/pixel\n",
    "    threshold_counts = threshold * np.median(counts)\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Median {np.median(counts)} objects/pixel')\n",
    "        print(f'Only count pixels with more than {threshold_counts} objects')\n",
    "\n",
    "    significant_pixels, = np.where(counts > threshold_counts)\n",
    "    area_pixel = hp.nside2pixarea(nside, degrees=True) * u.deg**2\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Pixel size ~ {hp.nside2resol(nside, arcmin=True) * u.arcmin:0.2g}')\n",
    "        print(f'nside: {nside}, area/pixel: {area_pixel:0.4g}, num significant pixels: {len(significant_pixels)}')\n",
    "\n",
    "    area = len(significant_pixels) * area_pixel\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Total area: {area:0.7g}')\n",
    "    \n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_dc2 = calculate_area(df)\n",
    "print(f'DC2 Run 2.2i area: {area_dc2:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Average density: {len(df)/area_dc2.to(\"arcmin**2\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.save(dc2_ra_dec_coverage, \"test.html\", backend=\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are the divots above the bright stars?\n",
    "\n",
    "There are clear pixels in the above map that have a notably lower density.  Are these from bright stars in those regions that are masking out a number of objects?  Not just saturated stars, but really bright ones.  This would be at a smaller resolution than the pixel size of the density map.\n",
    "\n",
    "Let's check the truth catalog with GCR Catalogs:\n",
    "`dc2_truth_run2.2i_star_truth_summary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_truth_catalog_name = \"dc2_truth_run2.2i_star_truth_summary.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GCRCatalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = GCRCatalogs.load_catalog(star_truth_catalog_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.list_all_quantities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_nanoJansky_to_mag(flux):\n",
    "    \"\"\"Convert calibrated nanoJansky flux to AB mag.\n",
    "    \"\"\"\n",
    "    #pylint: disable=C0103\n",
    "    AB_mag_zp_wrt_Jansky = 8.90  # Definition of AB\n",
    "    # 9 is from nano=10**(-9)\n",
    "    #pylint: disable=C0103\n",
    "    AB_mag_zp_wrt_nanoJansky = 2.5 * 9 + AB_mag_zp_wrt_Jansky\n",
    "\n",
    "    return -2.5 * np.log10(flux) + AB_mag_zp_wrt_nanoJansky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the conversion makes sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_nanoJansky_to_mag(1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stars = pd.DataFrame(cat.get_quantities(['ra', 'dec', 'flux_g', 'flux_r', 'flux_i']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in 'g', 'r', 'i':\n",
    "    all_stars[f\"mag_{f}\"] = convert_nanoJansky_to_mag(all_stars[f\"flux_{f}\"])\n",
    "    \n",
    "all_stars[\"g-r\"] = all_stars[\"mag_g\"] - all_stars[\"mag_r\"]\n",
    "all_stars[\"r-i\"] = all_stars[\"mag_r\"] - all_stars[\"mag_i\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_color_points = hv.Points(all_stars, kdims=[\"g-r\", \"r-i\"])\n",
    "color_color = datashade(color_color_points)\n",
    "\n",
    "color_mag_points = hv.Points(all_stars, kdims=[\"g-r\", \"mag_r\"])\n",
    "color_mag = datashade(color_mag_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_color + color_mag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two surprising features of the left plot:\n",
    "1. The streaks up and to the right.\n",
    "    These are the finite M-stars models that are then reddened by different amounts of dust, leading to the streaking.  This same reddening affects the other stars as well, but the warmer and hotter stars are distributed along a line parallel to the reddening vector (as an interesting piece of astrophysics that's the subject of a lecture in Astro classes).\n",
    "2. The curving downward.\n",
    "    These are various cool white dwarf models, some a bit more theoretical than observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crude simple selection of stars in area.\n",
    "# We're being generous instead of doing the geometry precisely\n",
    "\n",
    "min_ra, max_ra = dc2_run2x_wfd[2][0], dc2_run2x_wfd[3][0]\n",
    "min_dec, max_dec = dc2_run2x_wfd[2][1], dc2_run2x_wfd[0][1]\n",
    "\n",
    "stars = all_stars[(min_ra < all_stars[\"ra\"]) & (all_stars[\"ra\"] < max_ra) &\n",
    "                  (min_dec < all_stars[\"dec\"]) & (all_stars[\"dec\"] < max_dec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bright_stars = stars[stars[\"mag_r\"] < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bright_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = moll_ang2xy(bright_stars['ra'], bright_stars['dec'], mollweide=mollweide)\n",
    "bright_stars_ra_dec = hv.Points((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the same xticks, yticks <-> RA, Dec mapping as from above.\n",
    "bright_stars_ra_dec = bright_stars_ra_dec.opts(xlabel='RA', ylabel='Dec',\n",
    "                                               xticks=major_ticks_and_labels_x, yticks=major_ticks_and_labels_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bright_stars_ra_dec.opts(color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc2_ra_dec_coverage * bright_stars_ra_dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how the star selection was a bit generous over getting the geometry exactly right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate around with the Bokeh UI tools, I conclude that the bright stars aren't obviously responsible for the major visible divots at the large scale.\n",
    "\n",
    "But it was useful to think about how to extract items from the truth catalog and overlay them on the density plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-python-bleed",
   "language": "python",
   "name": "desc-python-bleed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
