{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Catalog Loading Example**\n",
    "\n",
    "Notebook for loading DC2 snapshot catalog data using the following 2 catalogs\n",
    "\n",
    "* **Galaxies:** baseDC2_snapshot_z1.01_v0.1\n",
    "* **DM Particles:** global/projecta/projectdirs/lsst/groups/CS/cosmoDC2/Outer_snapshots/z1.01/m000.mpicosmo.247\n",
    "\n",
    "First cell loads galaxy data, second cell loads DM data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Galaxy Data (Example 1)**\n",
    "\n",
    "To load the full galaxy catalog, you need the GCRCatalogs library. There are several ways to load galaxy positions. The best way to avoid memory errors is to use an iterator from the GCRCatalog reader. The first example iterates through all galaxies below a specified magnitude cut and saves the x, y, and z positions as arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import h5py\n",
    "genericio_path = (r\"/global/u2/s/samgolds/DC2-analysis/contributed/\"\n",
    "                  \"nonlinear_bias/genericio/python/\")\n",
    "gcrcatalogs_path = r\"/global/u2/s/samgolds/gcr-catalogs/\"\n",
    "\n",
    "sys.path.append(genericio_path)\n",
    "sys.path.append(gcrcatalogs_path)\n",
    "\n",
    "import GCRCatalogs\n",
    "import numpy as np\n",
    "import pyccl\n",
    "\n",
    "# Define helper function for keeping track of progress\n",
    "def progress_bar(cur_val, final_val):\n",
    "    \"\"\" \n",
    "    Function to keep track of progress during computations by displaying\n",
    "    a progress bar\n",
    "\n",
    "    Parameters:\n",
    "    cur_val (int/float): current iteration/value calculation is on\n",
    "    final_val (int/float): final iteration/value that calculation will take\n",
    "    \"\"\"\n",
    "\n",
    "    bar_length = 20\n",
    "    percent = float(cur_val) / final_val\n",
    "    arrow = '-' * int(round(percent * bar_length)-1) + '>'\n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "\n",
    "    sys.stdout.write(\"\\rProgress: [{0}]\"\n",
    "                     \" {1}%\".format(arrow + spaces, int(round(percent * 100))))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# Initialize galaxy catalog and cosmology\n",
    "cat_str = \"baseDC2_snapshot_z1.01_v0.1\"\n",
    "cat = GCRCatalogs.load_catalog(cat_str)\n",
    "\n",
    "COSMO, Z_RED_SHIFT = cat.cosmology, cat.redshift\n",
    "H0 = 71.0 # For conversions between Mpc and Mpc/h\n",
    "\n",
    "\n",
    "\"\"\"------------------------------------------EXAMPLE 1----------------------------------------------------\"\"\"\n",
    "# Load galaxy positions with r < 24.5 using iterator\n",
    "\n",
    "# Get catalog iterator\n",
    "cat_vals = cat.get_quantities([\"position_x\", \"position_y\", \"position_z\",  \"Mag_true_r_lsst_z0\"],\n",
    "                              return_iterator=True)\n",
    "mag_cut = 24.5\n",
    "x_positions = np.array([], dtype=float)\n",
    "y_positions = np.array([], dtype=float)\n",
    "z_positions = np.array([], dtype=float)\n",
    "\n",
    "for data_val in cat_vals:\n",
    "\n",
    "\n",
    "    r_Mag = data_val[\"Mag_true_r_lsst_z0\"]\n",
    "    r_mag = r_Mag+cat.cosmology.distmod(Z_RED_SHIFT).value\n",
    "\n",
    "    # Remove all entries below mag_cut and convert to Mpc/h for conv_coord\n",
    "    filtered_indices = np.where(r_mag < mag_cut)[0]\n",
    "    \n",
    "    x_positions = np.append(x_positions, data_val[\"position_x\"][filtered_indices])\n",
    "    y_positions = np.append(y_positions, data_val[\"position_y\"][filtered_indices])\n",
    "    z_positions = np.append(z_positions, data_val[\"position_z\"][filtered_indices])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Galaxy Data (Example 2)**\n",
    "\n",
    "Similar to first example, but saves positions to an HDF file locally. I already have several of the HDF5 files for various limiting r-band magnitudes saved in the following locations, so you won't need to run this unless you want a different limiting magnitude or more than just the positional data.\n",
    "\n",
    "* **r < 24.5:**  *'/global/cscratch1/sd/samgolds/gal_cat_24_5.h5'*\n",
    "* **r < 23:**  *'/global/cscratch1/sd/samgolds/gal_cat_23.h5'*\n",
    "* **r < 21:**  *'/global/cscratch1/sd/samgolds/gal_cat_21.h5'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"------------------------------------------EXAMPLE 2----------------------------------------------------\"\"\"\n",
    "# Load galaxy positions with r < 24.5 using iterator and save to HDF file\n",
    "\n",
    "# Get catalog iterator\n",
    "\n",
    "mag_cut = 24.5\n",
    "\n",
    "def get_n_galaxies(mag_cut):\n",
    "    \"\"\"\n",
    "    Function to determine the number of galaxies below a specific magnitude cut to pre-allocate memory for HD5.\n",
    "    There is probably some better way to avoid having to do this (i.e. dynamically change size of HDF file), but\n",
    "    this works and doesn't take too long to run on the galaxies.\n",
    "    \"\"\"\n",
    "    \n",
    "    cat_vals = cat.get_quantities([\"position_x\", \"position_y\", \"position_z\",  \"Mag_true_r_lsst_z0\"], \n",
    "                                  return_iterator=True)\n",
    "    n_gal = 0\n",
    "    \n",
    "    for data_val in cat_vals:\n",
    "        \n",
    "        r_Mag = data_val[\"Mag_true_r_lsst_z0\"]\n",
    "        r_mag = r_Mag+cat.cosmology.distmod(Z_RED_SHIFT).value\n",
    "\n",
    "        # Remove all entries below mag_cut and convert to Mpc/h for conv_coord\n",
    "        filtered_indices = np.where(r_mag < mag_cut)[0]\n",
    "\n",
    "        n_gal += len(filtered_indices)\n",
    "        \n",
    "    return n_gal\n",
    "\n",
    "\n",
    "print(\"Computing Number of Galaxies Below Mag Cut\")\n",
    "n_gal = get_n_galaxies(mag_cut)\n",
    "\n",
    "# Open an HDF file and proceed as in example 1, but save results\n",
    "with h5py.File('/global/cscratch1/sd/samgolds/gal_cat_24_5.h5' , 'w') as ff: \n",
    "    \n",
    "    pos = ff.create_dataset(\"Position\", dtype=(\"f8\"), shape=(n_gal, 3))\n",
    "    cur_index = 0\n",
    "\n",
    "    # Get catalog iterator\n",
    "    cat_vals = cat.get_quantities([\"position_x\", \"position_y\", \"position_z\",  \"Mag_true_r_lsst_z0\"], \n",
    "                                  return_iterator=True)\n",
    "    \n",
    "    for data_val in cat_vals:\n",
    "        \n",
    "        r_Mag = data_val[\"Mag_true_r_lsst_z0\"]\n",
    "        r_mag = r_Mag+cat.cosmology.distmod(Z_RED_SHIFT).value\n",
    "\n",
    "        # Remove all entries below mag_cut\n",
    "        filtered_indices = np.where(r_mag < mag_cut)[0]\n",
    "\n",
    "        positional_data = np.vstack((data_val[\"position_x\"][filtered_indices],\n",
    "                                     data_val[\"position_y\"][filtered_indices], \n",
    "                                     data_val[\"position_z\"][filtered_indices])).T\n",
    "        \n",
    "        # Write to dataset\n",
    "        n_pos = len(positional_data)\n",
    "        pos[cur_index:cur_index+n_pos] = positional_data\n",
    "        \n",
    "        cur_index += n_pos\n",
    "        \n",
    "        # Update progress\n",
    "        progress_bar(cur_index, n_gal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load DM Data**\n",
    "\n",
    "Explicitly loading the DM particles requires using genericio. The DM catalog is divided into 256 different files which need to be iterated over to load all the data. I load the data to an HDF5 file as before which can be accssed at *'/global/cscratch1/sd/samgolds/dm_cat.h5'*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import genericio\n",
    "\n",
    "def load_dark_matter_positions(file_str):\n",
    "    \"\"\"\n",
    "    Loads and applies preliminary filters to dark matter position data in Mpc\n",
    "    from a specified catalog and then applies a Gaussian kernel\n",
    "\n",
    "    Parameters:\n",
    "    file_str (string): location of file to load dark matter particles from\n",
    "    N (int):\n",
    "    \n",
    "    Returns:\n",
    "    pos_mat (N*N*N array): grid containing number of particles in box \n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data from catalog using genericio\n",
    "    x_data = np.array(genericio.gio_read(file_str, \"x\")[0])*100/H0\n",
    "    y_data = np.array(genericio.gio_read(file_str, \"y\")[0])*100/H0\n",
    "    z_data = np.array(genericio.gio_read(file_str, \"z\")[0])*100/H0\n",
    "\n",
    "    \n",
    "\n",
    "    return np.vstack((x_data, y_data, z_data)).T\n",
    "\n",
    "dark_matter_file_str = (\"/global/projecta/projectdirs/lsst/groups/CS/\"\n",
    "                        \"cosmoDC2/Outer_snapshots/z1.01/m000.mpicosmo.247\")\n",
    "\n",
    "N_part = 10765080312 # Number of total DM particles in the catalog (pre-determined)\n",
    "\n",
    "with h5py.File('/global/cscratch1/sd/samgolds/dm_cat.h5' , 'w') as ff:    \n",
    "    \n",
    "    pos = ff.create_dataset(\"Position\", dtype=(\"f8\"), shape=(10765080312, 3))\n",
    "    cur_index = 0\n",
    "\n",
    "    # Iterate through all 256 DM catalog files \n",
    "    for i in range(256):\n",
    "\n",
    "        # Load positions\n",
    "        positional_data =  load_dark_matter_positions(dark_matter_file_str+\"#\"+str(i))\n",
    "        \n",
    "        # Save positions\n",
    "        n_pos = positional_data.shape[0]\n",
    "        pos[cur_index:cur_index+n_pos] = positional_data\n",
    "        cur_index += n_pos\n",
    "\n",
    "        # Update progress\n",
    "        progress_bar(i, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Computing Galaxy and Matter Power Spectra Using Loaded Data**\n",
    "\n",
    "I compute power spectra using nbodykit, which utilizes streaming for h5 files (this is very useful in avoiding memory errors when computing matter cross and auto power spectra as the DM file is very large). It can probably compute 2-point correlation functions as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbodykit.lab import *\n",
    "from nbodykit import style\n",
    "\n",
    "box_size = 3000*100/H0\n",
    "\n",
    "# Grid size to compute power spectra on\n",
    "N = 1536\n",
    "\n",
    "# Location of saved h5 positions for galaxies and DM\n",
    "gal_cat_str ='/global/cscratch1/sd/samgolds/gal_cat_24_5.h5'\n",
    "dm_cat_str = '/global/cscratch1/sd/samgolds/dm_cat.h5'\n",
    "\n",
    "\n",
    "def load_mesh_h5(cat_str, N):\n",
    "    \"\"\"Helper function to create nbodykit mesh from h5 file\"\"\"\n",
    "    \n",
    "    print(\"Initializing H5 Catalog\")\n",
    "    f =  HDFCatalog(cat_str)\n",
    "    f.attrs['BoxSize'] = box_size\n",
    "    \n",
    "    print(\"Constructing Mesh\")\n",
    "    return  f.to_mesh(Nmesh=N, compensated=True)    \n",
    "\n",
    "\n",
    "# Construct galaxy mesh (should be very fast)\n",
    "mesh_gal = load_mesh_h5(gal_cat_str, N)\n",
    "mesh_dm = load_mesh_h5(dm_cat_str, N)\n",
    "\n",
    "# Compute power spectra (for galaxy-galaxy this could take around an hour, for galaxy/matter and matter-matter could take up to 5)\n",
    "print(\"Computing Power:\")\n",
    "P_3D_gg = FFTPower(mesh_gal, mode='1d', dk=0.01, kmin=0.001)\n",
    "P_3D_mm = FFTPower(mesh_dm, mode='1d', dk=0.01, kmin=0.001)\n",
    "P_3D_mg = FFTPower(mesh_dm, second=mesh_gal, mode='1d', dk=0.01, kmin=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-anzestack]",
   "language": "python",
   "name": "conda-env-.conda-anzestack-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
