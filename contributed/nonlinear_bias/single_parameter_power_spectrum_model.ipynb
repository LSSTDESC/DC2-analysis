{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2D Power Spectrum Calculation Example:**\n",
    "\n",
    "This notebook features an example calculation of the 2D power spectrum using the *baseDC2_snapshot_z0.15_v0.1* catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import Files and Setup Configuration:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GCRCatalogs\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import pyccl\n",
    "import sys\n",
    "\n",
    "from halotools.mock_observables import apply_zspace_distortion\n",
    "from scipy.constants import speed_of_light\n",
    "from scipy.stats import chi2 as chi2func\n",
    "\n",
    "sns.set(style = \"ticks\")\n",
    "pi = np.pi\n",
    "\n",
    "%config IPCompleter.greedy = True\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "# Load Appropriate Catalog\n",
    "#cat = GCRCatalogs.load_catalog(\"baseDC2_snapshot_z0.15_v0.1_small\")\n",
    "cat = GCRCatalogs.load_catalog(\"baseDC2_snapshot_z0.15_v0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load Position Data and Apply Preliminary Cuts:**\n",
    "\n",
    "Load the data appropriately depending on user-defined cuts. X and Y positions are cut equally to define a square 2D grid (position data limits are listed below). Additionally, removes all galaxies with $r_{mag} > 24.5$.\n",
    "\n",
    "**Small Catalog Limits\\*:**\n",
    "\n",
    "| X | Y | Z |\n",
    "| --- | --- | --- |\n",
    "| [0, 354.7] | [0, 425.0] | [0, 846.5] |\n",
    "\n",
    "**Full Catalog Limits:**\n",
    "\n",
    "| X | Y | Z |\n",
    "| --- | --- | --- |\n",
    "| [0, 4231.7] | [0, 4232.25] | [0, 4231.6] |\n",
    "\n",
    "\\* The small catalog has 40 positional entries with X, Y, or Z around 4000 Mpc, but after removing these entries, the above boundaries are identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize/Load Cosmology Parameters\n",
    "z_red_shift = cat.redshift\n",
    "cosmo = cat.cosmology # astropy cosmology object\n",
    "h = cosmo.h\n",
    "\n",
    "#Initialize a PyCCL cosmology object for future calculations\n",
    "cosmo_ccl = pyccl.Cosmology(h = cosmo.h, sigma8 = cosmo.sigma8, \n",
    "                            Omega_g = cosmo.Ogamma0, Omega_k = cosmo.Ok0, \n",
    "                            Omega_c =  cosmo.Odm0, Omega_b = cosmo.Ob0, \n",
    "                            n_s = cosmo.n_s, Neff = cosmo.Neff)\n",
    "\n",
    "\n",
    "# Setup box bounds (Mpc) \n",
    "\n",
    "# Not loading full z window to save time is justified since Gaussian kernel \n",
    "# will select window of around 2000 Mpc)\n",
    "min_z = 1116\n",
    "max_z = 3116\n",
    "min_x_y = 0\n",
    "max_x_y = 4232\n",
    "\n",
    "# min_z = 0\n",
    "# max_z = 800\n",
    "# min_x_y = 0\n",
    "# max_x_y = 350\n",
    "\n",
    "print(\"Loading quantitites\")\n",
    "cat_quantities = cat.get_quantities([\"position_x\", \"position_y\", \"position_z\", \n",
    "                                     \"Mag_true_r_lsst_z0\"], \n",
    "                                    filters=[\"position_z > {}\".format(min_z), \n",
    "                                             \"position_z < {}\".format(max_z), \n",
    "                                             \"position_x < {}\".format(max_x_y),\n",
    "                                             \"position_x > {}\".format(min_x_y),\n",
    "                                             \"position_y < {}\".format(max_x_y),\n",
    "                                             \"position_y > {}\".format(min_x_y)])\n",
    "\n",
    "\n",
    "print(\"Selecting appropriate quantity region\")\n",
    "\n",
    "# Convert absolute to apparent magnitude\n",
    "r_Mag = cat_quantities[\"Mag_true_r_lsst_z0\"]\n",
    "r_mag = r_Mag+cosmo.distmod(z_red_shift).value  \n",
    "filtered_indices = np.where(r_mag < 24.5)[0]\n",
    "\n",
    "# Clear magnitude arrays\n",
    "del r_mag\n",
    "del r_Mag\n",
    "\n",
    "# Account for peculiar velocity redshift distortions\n",
    "x_data = cat_quantities[\"position_x\"][filtered_indices]\n",
    "y_data = cat_quantities[\"position_y\"][filtered_indices]\n",
    "z_data = cat_quantities[\"position_z\"][filtered_indices]\n",
    "\n",
    "del cat_quantities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Filter Position Data with Gaussian Kernel:**\n",
    "\n",
    "Apply a Gaussian kernel to the z position data and then select galaxies acccording to a Gaussian kernel defined as $e^{-\\frac{(z-\\bar{z})^2}{2\\sigma_\\chi^2}}$, where $\\bar{z}$ is the average z position, $\\sigma_\\chi = \\frac{c}{H(z)}\\sigma_z,$ and $\\sigma_z \\approx 0.05(1+z_{redshift})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute standard deviations for establishing Gaussian\n",
    "sigma_z = 0.05*(1+z_red_shift)\n",
    "H_z = cosmo.H(z_red_shift).value\n",
    "c_km_s = speed_of_light/10**3 # speed of light in km/s\n",
    "sigma_chi = c_km_s/H_z*sigma_z\n",
    "\n",
    "\n",
    "# Apply Gaussian kernel\n",
    "z_bar = np.mean(z_data)\n",
    "cutoffs = np.random.uniform(0, 1, len(z_data))\n",
    "\n",
    "mask_ind = np.where(cutoffs < np.exp(-(z_data-z_bar)**2/(2*sigma_chi**2)))[0]\n",
    "\n",
    "x_masked = x_data[mask_ind]\n",
    "y_masked = y_data[mask_ind]\n",
    "z_masked = z_data[mask_ind]\n",
    "\n",
    "# Calculate galaxy density\n",
    "n_bar = len(x_masked)/(max_x_y-min_x_y)**2\n",
    "\n",
    "\n",
    "#----------------------------Begin Plotting----------------------------#\n",
    "# Plot masked and unmasked histograms\n",
    "fig = plt.figure(figsize=(10,6.6))\n",
    "n_bins = 75\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "plt.hist(x_data, bins = n_bins, alpha  = 0.5, color = \"navy\")\n",
    "plt.title(\"X Distribution\", fontweight = \"bold\")\n",
    "plt.xlabel(\"X Coordinate [Mpc]\")\n",
    "plt.ylabel(\"Entries \")\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "plt.hist(y_data, bins = n_bins, alpha = 0.5);\n",
    "plt.title(\"Y Distribution\", fontweight = \"bold\")\n",
    "plt.xlabel(\"Y Coordinate [Mpc]\")\n",
    "plt.ylabel(\"Entries \")\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "plt.hist(z_data, bins = n_bins, alpha = 0.5, color = \"silver\");\n",
    "plt.title(\"Z Distribution\", fontweight = \"bold\")\n",
    "plt.xlabel(\"Z Coordinate [Mpc]\")\n",
    "plt.ylabel(\"Entries \")\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "plt.hist(x_masked, bins = n_bins, alpha  = 0.5, color = \"navy\")\n",
    "plt.title(\"X Distribution (Mask)\",fontweight = \"bold\")\n",
    "plt.xlabel(\"X Coordinate [Mpc]\")\n",
    "plt.ylabel(\"Entries \")\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "plt.hist(y_masked, bins = n_bins, alpha = 0.5);\n",
    "plt.title(\"Y Distribution (Mask)\", fontweight = \"bold\")\n",
    "plt.xlabel(\"Y Coordinate [Mpc]\")\n",
    "plt.ylabel(\"Entries \")\n",
    "\n",
    "plt.subplot(2,3,6)\n",
    "plt.hist(z_masked, bins = n_bins, alpha = 0.5, color = \"silver\");\n",
    "plt.title(\"Z Distribution (Mask)\", fontweight = \"bold\")\n",
    "plt.xlabel(\"Z Coordinate [Mpc]\")\n",
    "plt.ylabel(\"Entries \")\n",
    "\n",
    "sigma_chi_str = \"$\\sigma_\\chi$ = {}\".format(np.round(sigma_chi, 1))\n",
    "\n",
    "# Overlay Gaussian\n",
    "z_gaussian = np.linspace(min_z, max_z, 200)\n",
    "exp_z = 1/(np.sqrt(2*pi)*sigma_chi)*np.exp(-(z_gaussian-z_bar)**2/(2*sigma_chi**2))\n",
    "\n",
    "bin_width = (max_z - min_z)/n_bins\n",
    "\n",
    "# Rescale by accounting for the fact that the data do not fulfill the entire Gaussian \n",
    "# and by multiplying the normalized pdf by bin_width*len(data)\n",
    "std_offset = (max_z-min_z)/(2*sigma_chi)\n",
    "rel_area = scipy.stats.norm.cdf(std_offset)-scipy.stats.norm.cdf(-std_offset)\n",
    "exp_z *= (bin_width*len(z_masked))/rel_area\n",
    "\n",
    "plt.plot(z_gaussian, exp_z, '--', color = 'k')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Get Matter Power-Spectrum From Data:**\n",
    "\n",
    "Code cell below defines a method for calculating the 2D power spectrum for x and y data with a specified resolution size *N* by computing the over-density field, 2-point correlation function, and then applying a 2D FFT. Additionally, a method is defined for averaging power spectrum values in bins of wavenumbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pow_spec(x_data, y_data,  N):\n",
    "    \n",
    "    \"\"\" Calculates the 2D power spectrum from data with specified grid size.\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    x_data (np float array): Array containing x positions of galaxies in Mpc\n",
    "    y_data (np float array): Array containing y positions of galaxies in Mpc\n",
    "    N (int): Integer representing the grid size for the power spectrum calculation\n",
    "    \n",
    "    Returns:\n",
    "    k_vals (np float array): array containing the returned wave numbers in Mpc^-1\n",
    "    p_k (np float array): array containing the returned power spectrum values\n",
    "    \"\"\"\n",
    "    \n",
    "    x_min = np.floor(x_data.min())\n",
    "    x_max = np.ceil(x_data.max())\n",
    "    x_width = x_max-x_min\n",
    "    y_width = x_width\n",
    "    \n",
    "    # Initialize Grid\n",
    "    grid_matrix = np.histogram2d(x_data, y_data, N)[0]\n",
    "    \n",
    "    # Get the number of galaxies and set amount of data points per bin\n",
    "    n_g = len(x_data)\n",
    "    p_bin = (int) (n_g/10000) \n",
    "    \n",
    "    delta_x = x_width/N\n",
    "    delta_y = y_width/N\n",
    "               \n",
    "    # Convert grid to represent over_density\n",
    "    p_bar = n_g/N**2 # No. galaxies expected per bin\n",
    "    p_bar_mat = p_bar*np.ones_like(grid_matrix)\n",
    "\n",
    "    delta = 1/p_bar*(grid_matrix-p_bar_mat) \n",
    "\n",
    "    # Compute variance in delta for cross-checking\n",
    "    var_delta = np.var(delta.flatten())\n",
    "\n",
    "    #Get frequency values\n",
    "    f_value = np.fft.fftfreq(N)\n",
    "    kx_mat = np.outer(np.ones(N), 2.0*pi*f_value/delta_x)\n",
    "    ky_mat = np.outer(2.0*pi*f_value/delta_y, np.ones(N))\n",
    "\n",
    "    # Construct matrix of wave numbers\n",
    "    k_mat = np.sqrt(kx_mat**2+(ky_mat)**2)\n",
    "\n",
    "    # Perform fourier transform\n",
    "    delta_k = np.fft.fft2(delta)\n",
    "\n",
    "    # Calculate power spectrum\n",
    "    pow_spec = np.real(delta_k*np.conj(delta_k))\n",
    "    p_k = pow_spec.flatten()/(N**2*N**2/(x_width*y_width))\n",
    "\n",
    "\n",
    "    # Construct and rescale wave number axis\n",
    "    k_vals = k_mat.flatten()\n",
    "    k_vals = k_vals[0:len(p_k)]\n",
    "    \n",
    "    # Remove zero order mode on return\n",
    "    return k_vals[1:], p_k[1:]\n",
    "\n",
    "def average_data(k_vals, p_vals, n_bins):\n",
    "    \"\"\" Averaged power spectrum and wave numbers into ~n_bins (averaging is not \n",
    "    always exact since empty bins are removed)\n",
    "    \n",
    "    Parameters:\n",
    "    k_vals (np float array): Array containing wave numbers in Mpc^-1\n",
    "    p_vals (np float array): Array containing power spectrum associated with k_vals\n",
    "    n_bins (int): Integer representing the desired number of bins to average into\n",
    "    \n",
    "    Returns:\n",
    "    averaged_k (np float array): arrray containing averaged wave numbers\n",
    "    averaged_p (np float array): array containing the averaged power spectrum\n",
    "    N_modes (np int array): array containing the number of data points in each k bin\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sort power spectrum by k\n",
    "    k_p_k = (np.vstack((k_vals, p_vals))).T\n",
    "    k_p_k = k_p_k[k_p_k[:,0].argsort()]\n",
    "\n",
    "    # Extract sorted values\n",
    "    k_vals = k_p_k.T[0]\n",
    "    p_k = k_p_k.T[1]\n",
    "    \n",
    "    n_modes, hist_bins = np.histogram(k_vals, bins= n_bins)\n",
    "    averaged_k = hist_bins+hist_bins[1]/2 # Get average wavenumber of each bin\n",
    "    averaged_k = averaged_k[0:n_bins] # Remove last bin since this is just upper limit\n",
    "    averaged_p = np.zeros_like(averaged_k) # Construct array for power spectrum values \n",
    "\n",
    "    # Remove bins with no modes\n",
    "    averaged_k = averaged_k[np.where(n_modes != 0)]\n",
    "    averaged_p = averaged_p[np.where(n_modes!=0)]\n",
    "    n_modes = n_modes[np.where(n_modes!=0)]\n",
    "    \n",
    "    low_ind = 0\n",
    "    \n",
    "    # Fill each averaged power spectrum bin\n",
    "    for ind, n_mode in enumerate(n_modes):\n",
    "        averaged_p[ind] = np.mean(p_k[low_ind:low_ind+n_mode])\n",
    "        low_ind += n_mode\n",
    "\n",
    "    return averaged_k, averaged_p, n_modes\n",
    "\n",
    "def progressBar(cur_val, final_val):\n",
    "    \"\"\" Simple function to keep track of progress in computations\n",
    "    \n",
    "    Parameters:\n",
    "    cur_val (int/float): Current value that calculation is on (normally iteration index)\n",
    "    final_val (int/float): Final value that calculation will take (normally num. iterations) \n",
    "    \"\"\"\n",
    "    bar_length=20\n",
    "    percent = float(cur_val) / final_val\n",
    "    arrow = '-' * int(round(percent * bar_length)-1) + '>'        \n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "    \n",
    "    sys.stdout.write(\"\\rProgress: [{0}] {1}%\".format(arrow + spaces, int(round(percent * 100))))\n",
    "    sys.stdout.flush() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Compute and Average Power Spectrum Over a Range of N:**\n",
    "\n",
    "Calculate the power spectrum for an array of resolutions to get an estimate over a larger range of wavenumbers and averages the results after calculation in bins of wavenumber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of dimensions, N, to compute the power spectrum over \n",
    "#n_range = 2**np.arange(6, 15)\n",
    "n_range = [2**14]\n",
    "\n",
    "# Construct arrays to store total data from each grid size\n",
    "k_bar_total = np.array([])\n",
    "p_k_bar_total = np.array([])\n",
    "n_modes_total = np.array([])\n",
    "\n",
    "for i, n in enumerate(n_range):\n",
    "    \n",
    "    # Updat progress\n",
    "    progressBar(i, len(n_range))  \n",
    "    \n",
    "    k_bar, p_k_bar = calculate_pow_spec(x_masked, y_masked,  n)\n",
    "    \n",
    "    #k_bar, p_k_bar, n_modes = average_data(k_bar, p_k_bar, 1024)\n",
    "    \n",
    "    \n",
    "    k_bar_total = np.append(k_bar_total, k_bar)\n",
    "    p_k_bar_total = np.append(p_k_bar_total, p_k_bar)\n",
    "\n",
    "    # Update progress\n",
    "    progressBar(i+1, len(n_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-average Data\n",
    "n_bins = 1024\n",
    "k_bar_avg, p_k_bar_avg, n_modes_avg = average_data(k_bar_total, p_k_bar_total, n_bins)\n",
    "\n",
    "# Remove zero order mode\n",
    "k_bar_avg = k_bar_avg\n",
    "p_k_bar_avg = p_k_bar_avg\n",
    "n_modes_avg = n_modes_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Compute 2D Power Spectrum Projections:**\n",
    "\n",
    "Code cell below defines a series of methods to construct the 2D power spectrum from CCL models using the following procedure:\n",
    "\n",
    "1. Define the power spectrum $P(k_\\parallel, k_\\perp)$ using the linear matter p\n",
    "ower spectrum function in pyCCL\n",
    "2. Integrate over a range of values for $k_\\perp$ using the integral defined below to obtain a theoretical estimate for the 2D matter power spectrum\n",
    "$$P_{matter}(k_\\perp) = \\frac{1}{2\\pi}\\int\\limits_{0}^{\\infty}P(k_\\parallel, k_\\perp)e^{-k_\\parallel^2\\sigma_\\chi^2}dk_\\parallel$$\n",
    "3. Get 2D galaxy power spectrum using the following model:\n",
    "$$P_{gal}(k_\\perp) = b_1^2P_{matter}(k_\\perp)+\\frac{1}{\\bar{n}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrand_function(k_par, k_perp, cosmo_ccl, cosmo, z, sigma_chi, linear):\n",
    "    \"\"\" Returns the computed integrand (P(k_par,k_perp)exp(-k_par^2*sigma_chi^2)). \n",
    "    where P(k_par, k_perp) is computed using either teh Pyccl linear or non-linear\n",
    "    matter power spectrum depending on input\n",
    "    \n",
    "    Parameters:\n",
    "    k_par (float): Parallel wave number to be integrated over numerically\n",
    "    k_perp (np float array): Array containing the perpendicular wave numbers\n",
    "    cosmo_ccl (pyccl cosmology) : pyccl cosmology object used for calculating power spectrum\n",
    "    cosmo (astropy cosmology): astropy cosmology object used to get the scale factor \n",
    "    z (float): redshift value of the catalog used to compute the scale factor\n",
    "    sigma_chi (float): sigma_chi used in Gaussian kernel\n",
    "    linear (bool): boolean represented whether to use linear or non-linear model\n",
    "    \n",
    "    Returns:\n",
    "    float representing the calcualted integrand value\n",
    "    \"\"\"\n",
    "    \n",
    "    if linear:\n",
    "        P_k = pyccl.linear_matter_power(cosmo_ccl, np.sqrt(k_perp**2+k_par**2), \n",
    "                                    cosmo.scale_factor(z))\n",
    "    else:\n",
    "        P_k = pyccl.nonlin_matter_power(cosmo_ccl, np.sqrt(k_perp**2+k_par**2), \n",
    "                                    cosmo.scale_factor(z))\n",
    "        \n",
    "    return P_k*np.exp(-(k_par*sigma_chi)**2)\n",
    "\n",
    "\n",
    "# Define linear and non-linear functions to compute integral\n",
    "integrator = np.vectorize(lambda k_perp: 1/(2*pi)*scipy.integrate.quad(\n",
    "    integrand_function, 0, 0.3, args=(k_perp, cosmo_ccl, cosmo, \n",
    "                                      z_red_shift, sigma_chi, True))[0])\n",
    "\n",
    "integrator_nl = np.vectorize(lambda k_perp: 1/(2*pi)*scipy.integrate.quad(\n",
    "    integrand_function, 0, 0.3, args=(k_perp, cosmo_ccl, cosmo, \n",
    "                                      z_red_shift, sigma_chi, False))[0])\n",
    "\n",
    "\n",
    "def get_pow_2d(k_perp, integrator, b_1, n_bar):\n",
    "    \"\"\"Function to get the 2D galaxy power spectrum using the following model:\n",
    "    P_gal = b_1^2*P_matter+1/n_bar\n",
    "    \n",
    "    Parameters:\n",
    "    k_perp (np float array): Array containing the perpendicular wave numbers\n",
    "    integrator (vectorized function): function to compute integral using linear or\n",
    "    non-linear power spectrum\n",
    "    b_1 (float): bias term \n",
    "    n_bar (float): average galaxy density to account for shot-noise\n",
    "    \n",
    "    Returns:\n",
    "    np float array representing the 2D power spectrum calculated over a given k_perp\n",
    "    \"\"\"\n",
    "    \n",
    "    return b_1**2*integrator(k_perp)+1/n_bar\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Plot 2D Power Spectrum Data and Models:**\n",
    "\n",
    "Plots the averaged 2D power spectrum data with appropriately fit models ($P_{gal}(k_\\perp) = b_1^2P_{matter}+\\frac{1}{\\bar{n}}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a bias term b_1 for the model P_gal = b_1^2*P_matter+1/n_bar\n",
    "b_1 = np.sqrt( 1.86)\n",
    "\n",
    "# Compute average variance in the data\n",
    "var_p_k_bar_avg = 2*p_k_bar_avg**2/n_modes_avg\n",
    "\n",
    "# Plot data for 2D linear and non-linear full range approx.\n",
    "plt.figure(figsize = (16,8))\n",
    "k_theoretical = np.linspace(np.min(k_bar_avg), \n",
    "                            1.1*np.max(k_bar_avg), 10000)\n",
    "plt.plot(k_theoretical, get_pow_2d(k_theoretical, integrator, b_1, n_bar), \n",
    "         color = \"k\",  linestyle  = \"dashed\",label = \"PyCCL Linear MPS\")\n",
    "\n",
    "plt.plot(k_theoretical, get_pow_2d(k_theoretical, integrator_nl, b_1, n_bar), \n",
    "         color = \"r\" , linestyle = \":\",label = \"PyCCL Non-Linear MPS\")\n",
    "\n",
    "plt.errorbar(k_bar_avg[0:-2], p_k_bar_avg[0:-2], yerr=np.sqrt(var_p_k_bar_avg)[0:-2], marker = '.', \n",
    "             color = \"lightslategrey\", linestyle = \"none\", markersize = 6, \n",
    "             ecolor = 'k', elinewidth = 1, capsize=2, markeredgewidth=1,\n",
    "             label = \"Averaged Power Spectrum\")\n",
    "\n",
    "\n",
    "plt.hlines(1/n_bar, 0, np.max(k_bar_avg), label = r\"$\\frac{1}{n}$\", linewidth = 1, linestyle = \"dashed\")\n",
    "\n",
    "plt.title(\"Computed 2D Power Spectrum\", fontweight = \"bold\")\n",
    "plt.xlabel(r\"$k_\\perp  \\ [Mpc^-1]$\")\n",
    "plt.ylabel(r\"$\\left\\langle P_{2D}(k)\\right\\rangle \\ [Mpc^2]$\")\n",
    "plt.legend(loc = \"upper right\", fontsize = 12) \n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Fit Power Spectrum with Single Paramater:**\n",
    "\n",
    "Determines the optimal parameter $b_1$ to fit the power spectrum upto varying $k_\\perp^{max}$ with the following relationship:\n",
    "$$P_{gal}(k_\\perp) = b_1^2P_{matter}+\\frac{1}{\\bar{n}}$$\n",
    "\n",
    "\n",
    "Maximizes the following log-likelihood expression\n",
    "* $\\log{(Likelihood)} = -(\\frac{\\chi^2}{2}+ \\sum\\limits_{i=1}^{nbins} \\log{(\\sigma_i}))$\n",
    "* $ \\chi^2= \\sum\\limits_{nbins} \\frac{(P_{theory}(k_\\perp) - P_{data}(k_\\perp))^2}{\\sigma^2}$\n",
    "* $\\sigma = P_{theory}(k_\\perp)\\sqrt\\frac{2}{Nmodes}$\n",
    "\n",
    "Compute cdf for the best fit $\\chi^2$,  given degrees of freedom, where d.o.f. = N_bins - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal solution guess\n",
    "b_1_guess = np.sqrt(1.7)\n",
    "\n",
    "\n",
    "def get_pow_2d(k_perp, integrator, b_1, n_bar):\n",
    "    \"\"\"Function to get the 2D galaxy power spectrum using the following model:\n",
    "    P_gal = b_1^2*P_matter+1/n_bar\n",
    "    \n",
    "    Parameters:\n",
    "    k_perp (np float array): Array containing the perpendicular wave numbers\n",
    "    integrator (vectorized function): function to compute integral using linear or\n",
    "    non-linear power spectrum\n",
    "    b_1 (float): bias term \n",
    "    n_bar (float): average galaxy density to account for shot-noise\n",
    "    \n",
    "    Returns:\n",
    "    np float array representing the 2D power spectrum calculated over a given k_perp\n",
    "    \"\"\"\n",
    "    \n",
    "    return b_1**2*integrator(k_perp)+1/n_bar\n",
    "\n",
    "\n",
    "\n",
    "def calc_chi_sq(b_1, k, p_k, integrator, n_bar, N_modes):\n",
    "    \"\"\"Computes the total chi squared value for a given set of data and parameters:\n",
    "    \n",
    "    Parameters:\n",
    "    b_1 (float): bias term over which we can minimize this function\n",
    "    k (np float array): Array containing the perpendicular wave numbers\n",
    "    p_k (np float array): Array containing power spectrum associated with k_vals\n",
    "    N_modes (np int array): Array containing the number of Fourier modes in each k bin\n",
    "    var_e (np float arary): Array containing the experimental variance from the data\n",
    "                            will be removed once theoretical variance is figured out\n",
    "    integrator (vectorized function): function to compute integral using linear or\n",
    "    n_bar (float): average galaxy density to account for shot-noise\n",
    "    \n",
    "    Returns:\n",
    "    float representing the summed chi_sq values\n",
    "    \"\"\"\n",
    "    \n",
    "     # Compute theoretical variance\n",
    "    p_theory = get_pow_2d(k, integrator, b_1, n_bar)\n",
    "    var_t = 2*p_theory**2/N_modes\n",
    "    \n",
    "    # Compute chi_sq\n",
    "    chi_sq = (p_k-p_theory)**2/var_t\n",
    "    \n",
    "    return chi_sq\n",
    "\n",
    "def neg_log_like(b_1, k, p_k, integrator, n_bar, N_modes):\n",
    "    \"\"\"Computes the total negative log likelihood for a given set of paramater/dat:\n",
    "    \n",
    "    Parameters:\n",
    "    b_1 (float): bias term over which we can minimize this function\n",
    "    k (np float array): Array containing the perpendicular wave numbers\n",
    "    p_k (np float array): Array containing power spectrum associated with k_vals\n",
    "    integrator (vectorized function): function to compute integral using linear or\n",
    "    n_bar (float): average galaxy density to account for shot-noise\n",
    "    N_modes (np int array): Array containing the number of Fourier modes in each k bin\n",
    "    \n",
    "    Returns:\n",
    "    float representing the total negative log likelihood\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute theoretical variance\n",
    "    p_theory = get_pow_2d(k, integrator, b_1, n_bar)\n",
    "    var_t = 2*p_theory**2/N_modes\n",
    "    \n",
    "    # Compute chi_sq\n",
    "    chi_sq = np.sum((p_k-p_theory)**2/var_t)\n",
    "    \n",
    "    neg_log_like = chi_sq/2+np.sum(np.log(np.sqrt(var_t)))\n",
    "    \n",
    "    return neg_log_like\n",
    "    \n",
    "# Create array of k max values to optimize upto\n",
    "k_max_arr = np.linspace(0.05, 2, 100)\n",
    "\n",
    "# Create empty arrays to fill with optimal parameters\n",
    "b_vals = np.zeros_like(k_max_arr)\n",
    "log_like_vals = np.zeros_like(k_max_arr)\n",
    "chi_sq_vals = np.zeros_like(k_max_arr)\n",
    "cdf = np.zeros_like(k_max_arr)\n",
    "\n",
    "for ind, k_max in enumerate(k_max_arr):\n",
    "    progressBar(ind, len(k_max_arr))  \n",
    "    \n",
    "    # Pick appropriate subset of values less than k_max_arr\n",
    "    subset_indices = np.where(k_bar_avg < k_max)\n",
    "    k_subset = k_bar_avg[subset_indices]\n",
    "    p_k_subset = p_k_bar_avg[subset_indices]\n",
    "    var_subset = var_p_k_bar_avg[subset_indices]\n",
    "    n_modes_subset = n_modes_avg[subset_indices]\n",
    "    \n",
    "    # Maxmize log likelihood\n",
    "    res = scipy.optimize.minimize(neg_log_like, b_1_guess, method='Nelder-Mead',\n",
    "                     args=(k_subset, p_k_subset,integrator, n_bar, n_modes_subset))\n",
    "\n",
    "    \n",
    "    # Compute chi^2\n",
    "    chi_2 = calc_chi_sq(res.x[0], k_subset, p_k_subset, integrator, n_bar, n_modes_subset)\n",
    "    \n",
    "    # Fill arrays\n",
    "    log_like_vals[ind] = res.fun\n",
    "    b_vals[ind] = res.x[0]\n",
    "    \n",
    "    chi_sq_vals[ind] = np.sum(chi_2)\n",
    "    #cdf[ind] = chi2func.pdf(np.sum(chi_2), df = len(k_subset)-1)\n",
    "    \n",
    "    progressBar(ind+1, len(k_max_arr))\n",
    "    \n",
    "\n",
    "# Calculate cdf\n",
    "#cdf = chi2func.cdf(chi_sq_vals, df = len(k_bar_avg)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Best Fit Plots:**\n",
    "\n",
    "Make various plots about the best fit data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup interval to plot\n",
    "k_max_val = 1.2\n",
    "b_1 = np.sqrt(1.85)\n",
    "subset_indices = np.where(k_max_arr < k_max_val)[0]\n",
    "# Plot data\n",
    "plt.figure(figsize = (14,14))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "k_theoretical = np.linspace(np.min(k_bar_avg), np.max(k_bar_avg), 2048)\n",
    "plt.plot(k_theoretical, get_pow_2d(k_theoretical, integrator, b_1, n_bar), \n",
    "         color = \"k\",  linestyle  = \"dashed\",label = \"PyCCL Linear PS\")\n",
    "\n",
    "plt.plot(k_theoretical, get_pow_2d(k_theoretical, integrator_nl, b_1, n_bar), \n",
    "         color = \"r\" , linestyle = \":\",label = \"PyCCL Non-Linear PS\")\n",
    "\n",
    "plt.errorbar(k_bar_avg, p_k_bar_avg, yerr=np.sqrt(var_p_k_bar_avg), marker = '.', \n",
    "             color = \"lightslategrey\", linestyle = \"none\", markersize = 6, \n",
    "             ecolor = 'k', elinewidth = 1, capsize=2, markeredgewidth=1,\n",
    "             label = \"Averaged Power Spectrum\")\n",
    "\n",
    "\n",
    "plt.hlines(1/n_bar, 0, np.max(k_bar_avg), label = r\"$\\frac{1}{n}$\", linewidth = 1, linestyle = \"dashed\")\n",
    "\n",
    "plt.title(\"PyCCL 2D Power Spectrum Models\", fontweight = \"bold\")\n",
    "plt.xlabel(r\"$k_\\perp$\")\n",
    "plt.ylabel(r\"$\\left\\langle P_{2D}(k)\\right\\rangle$\")\n",
    "plt.legend(loc = \"lower left\", fontsize = 12) \n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(k_max_arr[subset_indices], b_vals[subset_indices], '.')\n",
    "plt.title(r\"Optimal $b_1$ Values for Various $k_\\perp^{max} $  \", fontweight = \"bold\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"$k_\\perp^{max} [Mpc^{-1}]$\")\n",
    "plt.ylabel(\"$b_1$\")\n",
    "\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(k_max_arr[subset_indices], -log_like_vals[subset_indices], '.')\n",
    "plt.title(r\"Log-Likelihood and $k_\\perp^{max}$ relation\", fontweight = \"bold\")\n",
    "plt.ylabel(r\"max($\\log(\\mathcal{L})$)\")\n",
    "plt.xlabel(r\"$k_\\perp^{max} [Mpc^{-1}] $\")\n",
    "plt.xscale(\"log\")\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.title(r\"$\\chi^2$ and $k_\\perp^{max}$ relation\", fontweight = \"bold\")\n",
    "plt.ylabel(r\"min($\\chi^2$)\")\n",
    "plt.xlabel(r\"$k_\\perp^{max} [Mpc^{-1}] $\")\n",
    "plt.plot(k_max_arr[subset_indices], chi_sq_vals[subset_indices], '.')\n",
    "plt.xscale(\"log\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"optimal_b_chisq_min.png\", dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
