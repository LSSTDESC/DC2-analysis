{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Run 1.2i] Using the LSST Stack tools to do positional matching on coadd and src catalogs\n",
    "<br>Owner: **Ji Won Park** ([@jiwoncpark](https://github.com/LSSTDESC/DC2-analysis/issues/new?body=@jiwoncpark)) modified a similar notebook for Run 1.1p written by **Jim Chiang** ([@jchiang87](https://github.com/LSSTDESC/DC2-analysis/issues/new?body=@jchiang87)).\n",
    "<br>Created: **2019-02-27**\n",
    "<br> Last Run: **2019-04-18**\n",
    "\n",
    "**Note:** \n",
    "- This notebook reflects some schema changes that went into effect from Run 1.2i and, correspondingly, Generation 2 of Butler. If you're interested in Run 1.1p, go to Jim's original notebook [here](https://nbviewer.jupyter.org/github/LSSTDESC/DC2-analysis/blob/rendered/tutorials/matching_stack.nbconvert.ipynb) instead.\n",
    "- I also added some more annotations to guide DM beginners like me! They were mostly taken from function docstrings in [daf-persistence source code](https://github.com/lsst/daf_persistence) and [lsst skymap source code](https://github.com/lsst/skymap).\n",
    "\n",
    "In this notebook, we use the data butler to retrieve catalogs from coadd and visit-level analyses of Run 1.2i, and use the `lsst.afw.table.matchRaDec` function to do positional matching against galaxy truth info extracted from the protoDC2 extragalactic catalog v3.0, on which Run 1.2i was based.\n",
    "\n",
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import lsst.afw.geom as afw_geom\n",
    "import lsst.afw.table as afw_table\n",
    "from lsst.geom import radians\n",
    "import lsst.daf.persistence as dp\n",
    "import GCRCatalogs\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a subset of the truth catalog\n",
    "\n",
    "We said we wanted to match the \"observed\" objects in the Run 1.2i coadd and visit-level catalogs to the \"truth (input)\" objects in the protoDC2 catalog. The inconvenience with working directly with protoDC2, however, is that we need to first rotate its field to the Run 1.2i field in order to compare the positions. To bypass this step, we match Run 1.2i to the truth catalog instead of the protoDC2 catalog. If we wanted to retrieve the protoDC2 column information, we would simply join the truth catalog with the protoDC2 catalog based on the keys, `object_id` for the former and `galaxy_id` for the latter.\n",
    "\n",
    "We will download a small portion of the truth catalog and see which of the input objects we \"observe\" in the Run 1.2i coadd and visit-level catalogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the galaxy catalog data.\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    truth_gcr = GCRCatalogs.load_catalog('dc2_truth_run1.2_static')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We query the brightest objects, as they are more likely to be matched, by thresholding their r-band magnitudes. For speed purposes, we also downselect the sky region to an area that correspond to the subset of visit-level/coadd catalogs we will use in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_bp = 'r' # bandpass we'll use to query the brightest objects\n",
    "max_mag = 24.5\n",
    "brightest = '{} < {}'.format(our_bp, max_mag)\n",
    "within_region = ['ra < 56.2', 'ra > 55.8', 'dec < -28.4', 'dec > -28.85']\n",
    "truth_cols = ['object_id', 'ra', 'dec', 'r']\n",
    "truth_dict = truth_gcr.get_quantities(truth_cols, native_filters=[brightest,], filters=within_region)\n",
    "truth_df = pd.DataFrame(truth_dict)\n",
    "print(truth_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the positional matching code `lsst.afw.table.matchRaDec` mentioned above, `dict` or `pandas.DataFrame`-type catalogs won't do. We actually need to get our truth catalog in the `lsst.afw.table` format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_afw_table(bands=['r',]):\n",
    "    \"\"\"Initializes an afw table with magnitude column(s)\"\"\"\n",
    "    def define_mag_columns(bands):\n",
    "        \"\"\"Defines columns for given list of bands\"\"\"\n",
    "        Coldef = namedtuple('Coldef', 'name type doc'.split())\n",
    "        return [Coldef('mag_{}'.format(bp), float, '{}-magnitude'.format(bp)) for bp in bands]\n",
    "    # Some minimal schema\n",
    "    schema = afw_table.SourceTable.makeMinimalSchema()\n",
    "    # Define magnitude columns\n",
    "    mag_cols = define_mag_columns(bands=bands)\n",
    "    # Add magnitude columns to schema\n",
    "    for mag_coldef in mag_cols:\n",
    "        schema.addField(mag_coldef.name, type=mag_coldef.type, doc=mag_coldef.doc)\n",
    "    return afw_table.SourceCatalog(schema)\n",
    "\n",
    "truth_afw = make_afw_table(bands=['r',])\n",
    "for id_, ra_, dec_, mag_ in zip(*[truth_dict[col] for col in truth_cols]):\n",
    "    row = truth_afw.addNew()\n",
    "    row.set('id', id_)\n",
    "    row.set('coord_ra', afw_geom.Angle(ra_, afw_geom.degrees))\n",
    "    row.set('coord_dec', afw_geom.Angle(dec_, afw_geom.degrees))\n",
    "    row.set('mag_{}'.format(our_bp), mag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching Experiments\n",
    "\n",
    "Now that we have the tools we need, let's read in the Run 1.2i DRP catalog data.\n",
    "\n",
    "We first instantiate our Butler object. Butler manages a collection of datasets known as a \"repository.\" Each dataset has a `datasetType` identified by strings such as `'src'` or `'calexp'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data butlers for the src and coadd repositories.\n",
    "repo_path = '/global/cscratch1/sd/desc/DC2/data/Run1.2i_globus_in2p3_20181217/w_2018_39/rerun/multiband'\n",
    "butler = dp.Butler(repo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources or Objects?\n",
    "\n",
    "We can consider visit-level src catalog data, in which case we would define `datasetType='src'` and provide a query, or `dataId`, to the butler with (`visit`, `raftName`, `sensorName`) ids; or we can consider coadd object data, for which we would define `datasetType='coadd'` and provide a `dataId` with (`filter`, `tract`, `patch`) ids.\n",
    "\n",
    "Somewhat different flux models are available in the Run1.2i data for src catalogs versus coadd catalogs. We use `'base_PsfFlux'` for the flux model, as they are available in both.\n",
    "\n",
    "Let's start with the visit-level src catalog data. We first double-check the key definitions for the src catalog, as they change across run versions. (For example, we identified rafts with `raft` in Run 1.1p but now use `raftName`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching the src catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As mentioned above, here are the keys you can use to query the src catalog\n",
    "butler.getKeys(datasetType='src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now define a set of pre-selected IDs that uniquely defines a dataset. (Note: to check that some combination of data IDs corresponds to an available dataset, we can call `datasetExists()` on each `dataRef` object.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_visit = 219976\n",
    "our_raftName = 'R20'\n",
    "our_detector = 80\n",
    "\n",
    "our_dataId_src = {'visit': our_visit, 'filter': our_bp, 'raftName': our_raftName, 'detector': our_detector,}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function fetches the ID, ra, dec, and calibrated r-band magnitude of the visit-level/coadd catalog and saves the information in an afw table. \n",
    "It also does some querying to get objects that are (1) extended, (2) primary (no children), (3) not flux-flagged, and (4) bright. Galaxies can be selected as extended objects (or sources) using the `base_ClassificationExtendedness_value`. We use the model flag and flux to ensure that a flux value could be measured, and then apply a selection to ensure that we get deblended objects. Finally, we apply a relatively bright magnitude cut, to avoid confusion when performing the positional match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drp_catalog(butler, data_type, dataId):\n",
    "    \"\"\"Given a DRP dataset type and the dataId, \n",
    "    returns a afw table of the corresponding DRP catalog\"\"\"\n",
    "    if data_type=='src':\n",
    "        catalog_type = 'src'\n",
    "        calexp_type = 'calexp'\n",
    "    elif data_type=='obj':\n",
    "        catalog_type = 'deepCoadd_meas'\n",
    "        calexp_type = 'deepCoadd'\n",
    "    # Get the catalog for the given dataId\n",
    "    catalog = butler.get(datasetType=catalog_type, dataId=dataId)\n",
    "    # For calibration\n",
    "    calexp = butler.get(datasetType=calexp_type, dataId=dataId)\n",
    "    calib = calexp.getCalib()\n",
    "    calib.setThrowOnNegativeFlux(False)\n",
    "    # Filter is r for our purposes, but we can get it this way too\n",
    "    observed_filter = calexp.getInfo().getFilter().getName()\n",
    "    # Get primary extended objects with no flux flag\n",
    "    flux_model = 'base_PsfFlux' # schema v3\n",
    "    model_flux = catalog.get(flux_model + '_instFlux')\n",
    "    model_flag = catalog.get(flux_model + '_flag')\n",
    "    extendedness = catalog.get('base_ClassificationExtendedness_value')\n",
    "    num_children = catalog.get('deblend_nChild')\n",
    "    queried = catalog.subset((extendedness == 1) &\\\n",
    "                             (model_flag == False) &\\\n",
    "                             (model_flux > 0) &\\\n",
    "                             (num_children == 0))\n",
    "    # Extract the magnitude and further apply the depth cut\n",
    "    mag = calib.getMagnitude(queried[flux_model + '_instFlux'])\n",
    "    queried = queried.subset(mag < max_mag)\n",
    "    # Create the afw table of our catalog\n",
    "    drp_catalog = make_afw_table(bands=['r',]) # initialize\n",
    "    for row in queried:\n",
    "        new_rec = drp_catalog.addNew()\n",
    "        for name in 'id coord_ra coord_dec parent'.split():\n",
    "            new_rec.set(name, row[name])\n",
    "        new_rec.set('mag_{}'.format(observed_filter),\n",
    "                    calib.getMagnitude(row[flux_model + '_instFlux']))\n",
    "    return drp_catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many sources do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_src_catalog = get_drp_catalog(butler=butler, data_type='src', dataId=our_dataId_src)\n",
    "len(drp_src_catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching the coadd catalog\n",
    "\n",
    "Similarly, let's fetch the coadd object data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get which keys are available\n",
    "butler.getKeys(datasetType='deepCoadd_meas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to find a tract & patch combination that overlaps in sky area with the src catalog we just made. To do so, we fetch the `deepCoadd_skyMap` object and pass the four extreme corner coordinates of our src catalog to `findTractPatchList`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skymap = butler.get(datasetType='deepCoadd_skyMap', dataId=our_dataId_src)\n",
    "\n",
    "# radians\n",
    "min_ra, max_ra = np.min(drp_src_catalog['coord_ra']), np.max(drp_src_catalog['coord_ra'])\n",
    "min_dec, max_dec = np.min(drp_src_catalog['coord_dec']), np.max(drp_src_catalog['coord_dec'])\n",
    "\n",
    "coord_list = [\n",
    "    afw_geom.SpherePoint(min_ra * radians, min_dec * radians),\n",
    "    afw_geom.SpherePoint(max_ra * radians, min_dec * radians),\n",
    "    afw_geom.SpherePoint(max_ra * radians, max_dec * radians),\n",
    "    afw_geom.SpherePoint(min_ra * radians, max_dec * radians),\n",
    "]\n",
    "\n",
    "# This will be a list of tracts that overlap\n",
    "# Each tract entry will have its own list of patches that overlap\n",
    "tract_patches = skymap.findTractPatchList(coord_list)\n",
    "for tract, patches in tract_patches:\n",
    "    for patch in patches:\n",
    "        print(tract.getId(), patch.getIndex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Let us arbitrarily choose patch (1, 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_tract = 4850\n",
    "our_patch = '1,5' # Note the formatting! String with no space after the comma.\n",
    "\n",
    "our_dataId_obj = {'filter': our_bp, 'tract': our_tract, 'patch': our_patch,}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fetch our coadd catalog and turn it into an afw table. How many objects do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_obj_catalog = get_drp_catalog(butler=butler, data_type='obj', dataId=our_dataId_obj)\n",
    "len(drp_obj_catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing the Matching\n",
    "We can now carry out the spatial matching, and compute some quantities to plot. You can switch between `drp_obj_catalog` and `drp_src_catalog` to see the difference in matching between the coadd and src catalogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find positional matches within 100 milliarcseconds:\n",
    "matching_radius = afw_geom.Angle(0.1, afw_geom.arcseconds)\n",
    "src_matches = afw_table.matchRaDec(drp_src_catalog, truth_afw, matching_radius)\n",
    "obj_matches = afw_table.matchRaDec(drp_obj_catalog, truth_afw, matching_radius)\n",
    "print(len(obj_matches), len(src_matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`matches` is a list of `match` objects, each one containing an observed-true matchd galaxy pair. The code below shows how to work with these, looping over the matches and extracting information to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_differences(drp_catalog, matches, observed_filter):\n",
    "    num_matches = len(matches)    \n",
    "    # Compare magnitudes for matched objects:\n",
    "    drp_mag = np.zeros(num_matches, dtype=np.float)\n",
    "    truth_mag = np.zeros(num_matches, dtype=np.float)\n",
    "    sep = np.zeros(num_matches, dtype=np.float)\n",
    "    # Arrays for a quiver plot.\n",
    "    u = np.zeros(num_matches, dtype=np.float)\n",
    "    v = np.zeros(num_matches, dtype=np.float)\n",
    "    for i, match in enumerate(matches):\n",
    "        drp_mag[i] = match.first['mag_{}'.format(observed_filter)]\n",
    "        truth_mag[i] = match.second['mag_{}'.format(observed_filter)]\n",
    "        sep[i] = np.degrees(match.distance)*3600.*1000. # convert deg into milliarcseconds\n",
    "        u[i] = match.first['coord_ra'] - match.second['coord_ra']\n",
    "        v[i] = match.first['coord_dec'] - match.second['coord_dec']\n",
    "    print(\"Number of matches:\", len(matches))\n",
    "\n",
    "    # Start a 2x2 panel figure:\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    frame_axes = fig.add_subplot(111, frameon=False)\n",
    "    frame_axes.get_xaxis().set_ticks([])\n",
    "    frame_axes.get_yaxis().set_ticks([])\n",
    "\n",
    "    delta_mag = drp_mag - truth_mag  # Observed - True\n",
    "    # Upper Left: Histogram of match separations.\n",
    "    fig.add_subplot(2, 2, 1)\n",
    "    plt.hist(sep, range=(0, 100), histtype='step', bins=40)\n",
    "    plt.xlabel('separation (marcsec)')\n",
    "    plt.ylabel('entries / bin')\n",
    "\n",
    "    # Upper Right: Quiver plot of (DRP - galaxy_catalog) positions on the sky.\n",
    "    fig.add_subplot(2, 2, 2)\n",
    "    plt.quiver(np.degrees(drp_catalog['coord_ra']),\n",
    "               np.degrees(drp_catalog['coord_dec']), u, v)\n",
    "    plt.xlabel('RA (deg)')\n",
    "    plt.ylabel('Dec (deg)')\n",
    "\n",
    "    # Lower left: Difference in magnitudes vs true magnitude (mag_gc).\n",
    "    fig.add_subplot(2, 2, 3)\n",
    "    plt.errorbar(truth_mag, delta_mag, fmt='.')\n",
    "    plt.xlabel('True mag {}_gc'.format(observed_filter))\n",
    "    plt.ylabel('Mag difference ({0}_truth - {0}_drp)'.format(observed_filter))\n",
    "\n",
    "    # Difference in magnitudes vs separation.\n",
    "    fig.add_subplot(2, 2, 4)\n",
    "    plt.errorbar(sep, delta_mag, fmt='.')\n",
    "    plt.xlabel('separation (mas)')\n",
    "    plt.ylabel('Mag difference ({0}_truth - {0}_drp)'.format(observed_filter))\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_differences(drp_obj_catalog, obj_matches, our_bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_differences(drp_src_catalog, src_matches, our_bp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, here are the locations of sources/objects in the src/coadd catalogs we built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(drp_src_catalog['coord_ra'], drp_src_catalog['coord_dec'], alpha=0.5, label='src')\n",
    "plt.scatter(drp_obj_catalog['coord_ra'], drp_obj_catalog['coord_dec'], alpha=0.5, label='obj')\n",
    "plt.title(\"src and obj locations\")\n",
    "plt.xlabel('ra (rad)')\n",
    "plt.ylabel('dec (rad)')\n",
    "plt.xlim([0.974, 0.982])\n",
    "plt.ylim([-0.505, -0.495])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-stack",
   "language": "python",
   "name": "desc-stack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
