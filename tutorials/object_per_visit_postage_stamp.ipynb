{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DC2 Retrieve Forced Src catalogs of visit-level forced photometry from coadd Object catalog.  \n",
    "Michael Wood-Vasey\n",
    "\n",
    "### Learning Objectives\n",
    "After studying this Notebook you should be able to\n",
    "1. Retrieve the list of forced sources from a given tract, patch, filter.\n",
    "2. Compute the tract, patch for a given RA, Dec and skymap.\n",
    "2. Retrieve a postage stamp from the per-visit calibrated image (calexp) for a given object RA, Dec.\n",
    "3. Display a full coadd image and full calexp image with the location of an object highlighted.\n",
    "\n",
    "### Logistics\n",
    "Meant to be run on NERSC, where these data and environment are available.  But beyond having an environment with the stack, the only NERSC-specific aspect is the location of the data.  If you have your own set of data elsewhere, you just need to change the `repo` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import lsst.daf.persistence as dafPersist\n",
    "import lsst.afw.geom as afwGeom\n",
    "import lsst.afw.coord as afwCoord\n",
    "import lsst.afw.display as afwDisplay\n",
    "import lsst.afw.image as afwImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "backend = 'matplotlib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = '/global/projecta/projectdirs/lsst/global/in2p3/Run1.1/output'\n",
    "butler = dafPersist.Butler(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract = 4850\n",
    "patch = '4,5'\n",
    "\n",
    "filt = 'r'\n",
    "partial_data_id = {'tract': tract, 'patch': patch, 'filter': filt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 'forced_src'\n",
    "data_refs = butler.subset(datasetType=dataset_type, dataId=partial_data_id)\n",
    "data_ids = [dr.dataId for dr in data_refs\n",
    "           if butler.datasetExists(datasetType=dataset_type,\n",
    "                                   dataId=dr.dataId)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dId = {'tract': 4850, 'patch': '4,5', 'filter': 'r', 'visit': 181898, 'raft': '4,3', 'sensor': '0,2'}\n",
    "\n",
    "calibrated_exposure = butler.get(datasetType='calexp', dataId=dId)\n",
    "forced_src = butler.get(datasetType=dataset_type, dataId=dId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = forced_src.asAstropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib = calibrated_exposure.getCalib()\n",
    "calib.setThrowOnNegativeFlux(False)\n",
    "\n",
    "mag, mag_err = calib.getMagnitude(forced_src['base_PsfFlux_flux'],\n",
    "                                  forced_src['base_PsfFlux_fluxSigma'])\n",
    "cat['mag'] = mag\n",
    "cat['mag_err'] = mag_err\n",
    "cat['snr'] = np.abs(cat['base_PsfFlux_flux'])/cat['base_PsfFlux_fluxSigma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is per tract, so ~20k sources seems potentially reasonble.\n",
    "\n",
    "The `id` is the same `id` as in the coadd \"reference\" catalog (the result of merged detections from the individ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 1\n",
    "plt.figure(frame)\n",
    "plt.scatter(np.rad2deg(cat['coord_ra']),\n",
    "            np.rad2deg(cat['coord_dec']))\n",
    "plt.xlabel('RA [deg]')\n",
    "plt.ylabel('Dec [deg]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 2\n",
    "plt.figure(frame)\n",
    "plt.scatter(cat['mag'], cat['snr'])\n",
    "plt.xlabel('%s mag' % dId['filter'])\n",
    "plt.ylabel('S/N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a reasonable set of magnitudes and uncertainties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From one image to many\n",
    "Let's pick one of the Objects and go through all of the data IDs in that filter for the tract, patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_snr = cat[cat['snr'] > 25]\n",
    "obj = good_snr[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_images_for_object_id_from_data_ids(object_id, data_refs, dataset_type='forced_src'):\n",
    "    \"\"\"Take an Object ID and data_ref list and return matching data_refs that contain that object and exist\n",
    "    \n",
    "    Note:  This perhaps isn't quite the function you wanted.\n",
    "    You may have wanted a function that just took an object_id and filter.\n",
    "    But we'll get there.\n",
    "    \n",
    "    Note that we're being a little inefficient and loading each raft, sensor catalog\n",
    "    and checking to see if it contains the given ID.\n",
    "    It would likely be more efficient to just load the WCS for the Visit\n",
    "    and look up the raft, sensor.\n",
    "    \"\"\"\n",
    "    matching_data_refs = []\n",
    "    for data_ref in data_refs:\n",
    "        # Should add check to make sure it exists\n",
    "        if not data_ref.datasetExists(datasetType=dataset_type):\n",
    "            continue\n",
    "        cat = data_ref.get(datasetType=dataset_type)\n",
    "        if object_id in cat['id']:\n",
    "            matching_data_refs.append(data_ref)\n",
    "\n",
    "    return matching_data_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matching_data_refs = get_all_images_for_object_id_from_data_ids(obj['id'], data_refs, dataset_type='forced_src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ids = [dr.dataId for dr in matching_data_refs]\n",
    "print(data_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're still missing one step.\n",
    "\n",
    "How do we get the tract, patch for a given ObjectId or RA, Dec?\n",
    "\n",
    "You probably wanted to start with a given ObjectID from the Object (coadd) catalog and then get all of the images that include that object.\n",
    "\n",
    "To do this we\n",
    "1. Get the skymap for the coadd dataset (by default, `deepCoadd`)\n",
    "2. Use the skymap object to look up the tract\n",
    "3. Use the tract object to look up the patch\n",
    "4. Create a partial data Id dict and query the butler for `forced_src` catalogs that match this partial data Id.\n",
    "5. Go through each forced_src catalog in that tract, patch and save the ones that match the given Id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skymap = butler.get(datasetType='deepCoadd_skyMap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(skymap.findTractPatchList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra, dec = obj['coord_ra'], obj['coord_dec']\n",
    "# Note the catalog returns coord_ra, coord_dec in RADIANS\n",
    "radec = afwGeom.SpherePoint(ra, dec, afwGeom.radians)\n",
    "\n",
    "tracts_and_patches = skymap.findTractPatchList([radec])\n",
    "\n",
    "partial_data_ids = [{'tract': tractInfo.getId(), 'patch': '%d,%d' % patch.getIndex()} \\\n",
    "                    for tractInfo, patchList in tracts_and_patches\n",
    "                    for patch in patchList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = 'r'\n",
    "dataset_type = 'forced_src'\n",
    "\n",
    "data_refs = []\n",
    "for partial in partial_data_ids:\n",
    "    this_data_id = partial.copy()\n",
    "    this_data_id['filter'] = 'r'\n",
    "    print(this_data_id)\n",
    "    \n",
    "    these_data_refs = butler.subset(datasetType=dataset_type, dataId=this_data_id)\n",
    "    data_refs.extend(these_data_refs)\n",
    "\n",
    "data_ids = [dr.dataId for dr in data_refs\n",
    "           if butler.datasetExists(datasetType=dataset_type,\n",
    "                                   dataId=dr.dataId)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_data_refs = get_all_images_for_object_id_from_data_ids(obj['id'], data_refs, dataset_type='forced_src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ids = [dr.dataId for dr in matching_data_refs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could now use these data_ids to generate postage stamps from the calexps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout_ra_dec(butler, ra, dec, data_id, datasetType='calexp',\n",
    "                  cutoutSideLength=51, verbose=False,\n",
    "                  **kwargs):\n",
    "    \"\"\"\n",
    "    Produce a cutout from the given image at the given afw SpherePoint radec position.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    butler: lsst.daf.persistence.Butler\n",
    "        Servant providing access to a data repository\n",
    "    ra, dec: Right Ascension, Declination in decimal degrees\n",
    "        Coordinates of the center of the cutout.\n",
    "    data_id: Data Id\n",
    "    datasetType: string ['calexp']  \n",
    "    cutoutSideLength: float [optional] \n",
    "        Side of the cutout region in pixels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    MaskedImage\n",
    "    \"\"\"\n",
    "    cutoutSize = afwGeom.ExtentI(cutoutSideLength, cutoutSideLength)\n",
    "\n",
    "    radec = afwGeom.SpherePoint(ra, dec, afwGeom.degrees)\n",
    "\n",
    "    calexp = butler.get(datasetType, dataId=data_id)\n",
    "    xy = afwGeom.PointI(calexp.getWcs().skyToPixel(radec))\n",
    "    if verbose:\n",
    "        print(\"Making cutout at (x, y) {xy:} of size ({cutoutSize:}, {cutoutSize:})\".format({'xy': xy, 'cutoutSize': cutoutSize}))\n",
    "        print(xy, cutoutSize)\n",
    "\n",
    "    bbox = afwGeom.BoxI(xy - cutoutSize//2, cutoutSize)\n",
    "    \n",
    "    cutout_image = butler.get(datasetType+'_sub', bbox=bbox, immediate=True, dataId=data_id)\n",
    "    \n",
    "    return cutout_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cutout_image(butler, ra, dec, data_id,\n",
    "                         vmin=None, vmax=None, label=None,\n",
    "                         frame=None, display=None, backend='matplotlib',\n",
    "                         show=True, saveplot=False, savefits=False,\n",
    "                         datasetType='calexp'):\n",
    "    \"\"\"\n",
    "    Display a postage stamp for a given RA, Dec using LSST lsst.afw.display.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ra: float [degrees]\n",
    "    dec: float [degrees]\n",
    "    backend: string\n",
    "        Backend can be anything that lsst.afw.display and your configuration supports: \n",
    "        e.g. matplotlib, ds9, ginga, firefly.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    MaskedImage\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Parameters are the same as for make_cutout_image, except for the backend.\n",
    "    You definitely have the matplotlib backend.\n",
    "    ds9, ginga, and firefly can be set up but are non-trivial on the scale of a simple Notebook.\n",
    "    \"\"\"\n",
    "    cutout_image = cutout_ra_dec(butler, ra, dec, data_id, datasetType='deepCoadd')\n",
    "    if savefits:\n",
    "        if isinstance(savefits, str):\n",
    "            filename = savefits\n",
    "        else:\n",
    "            filename = 'postage-stamp.fits'\n",
    "        cutout_image.writeFits(filename)\n",
    "    \n",
    "    if display is None:\n",
    "        display = afwDisplay.Display(frame=frame, backend=backend)\n",
    "\n",
    "    radec = afwGeom.SpherePoint(ra, dec, afwGeom.degrees)\n",
    "    xy = cutout_image.getWcs().skyToPixel(radec)\n",
    "    \n",
    "    display.mtv(cutout_image)\n",
    "    display.scale(\"asinh\", \"zscale\")\n",
    "    display.dot('o', xy.getX(), xy.getY(), ctype='red')\n",
    "    display.show_colorbar()\n",
    "    \n",
    "    return cutout_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 3\n",
    "plt.figure(frame)\n",
    "\n",
    "ra_deg, dec_deg = np.rad2deg(ra), np.rad2deg(dec)\n",
    "\n",
    "for did in data_ids:\n",
    "    display_cutout_image(butler, ra_deg, dec_deg, did, datasetType='calexp', frame=frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the full image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "did = data_ids[0]\n",
    "coadd = butler.get('deepCoadd', dataId=did)\n",
    "calexp = butler.get('calexp', dataId=did)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 4\n",
    "plt.figure(frame)\n",
    "\n",
    "xy = coadd.getWcs().skyToPixel(radec)\n",
    "\n",
    "display = afwDisplay.Display(frame=frame, backend=backend)\n",
    "display.scale(\"asinh\", min=0, max=5)\n",
    "\n",
    "display.mtv(coadd)\n",
    "display.dot('o', xy.getX(), xy.getY(), ctype='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 5\n",
    "plt.figure(frame)\n",
    "\n",
    "xy = calexp.getWcs().skyToPixel(radec)\n",
    "\n",
    "display = afwDisplay.Display(frame=frame, backend=backend)\n",
    "display.scale(\"asinh\", min=-0.5, max=50)\n",
    "display.mtv(calexp)\n",
    "display.dot('o', xy.getX(), xy.getY(), ctype='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-stack",
   "language": "python",
   "name": "desc-stack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
