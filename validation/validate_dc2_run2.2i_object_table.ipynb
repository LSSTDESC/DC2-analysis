{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspection of DC2 Run 2.2i DR6 Object Table \n",
    "### Michael Wood-Vasey (@wmwv)\n",
    "### Last Verified to Run: 2020-06-11 by MWV\n",
    "\n",
    "Inspect the Run 2.2i DR6 Object Table\n",
    "\n",
    "This notebook is more qualitative rather than quantitative validation.  The analysis contained here should eventually grow beyond the confines of a notebook to include goals for the visualizations and numerical thresholds for specific quantities.\n",
    "\n",
    "1. Make 2D density plots (e.g., `hexbin`, `hist2d`, `datashader`) of\n",
    "    - ra, dec\n",
    "    - u-g, g-r\n",
    "    - r-i, g-r\n",
    "    - i-z, g-r\n",
    "    - z-y, g-r\n",
    "2. Make 1D density plots (e.g., `hist`, kernel-density-estimation)\n",
    "    - N({ugrizy})\n",
    "    - Shape parameters\n",
    "\n",
    "#### Run 2.2i DR6 as of 2020-06-04 includes  \n",
    "  * 78 tracts\n",
    "  * 52 million objects  \n",
    "  * 34 million objects with i-band SNR > 5\n",
    "\n",
    "Loading two columns of entire catalog from parquet file takes a few minutes, depending on memory load on the JupyterHub node.  It thus is often most useful to develop ones codes looking at only subsamples of the full DC2 datasets, whether that's considering just one tract, or taking a subsample of the full catalog.\n",
    "\n",
    "#### Quick Data Size estimates\n",
    "\n",
    "Loading 1 column stored as 64-bit floats on 64 million objects takes 512 MB of memory:\n",
    "\n",
    "8 bytes/column/row * 1 column * 64 million rows = 2^3 * 2^0 * 2^6 million bytes (MB) = 2^9 MB = 512 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can either use gcr-catalogs API: catalog = \"dc2_object_run2.2i_dr6a\"\n",
    "\n",
    "or can use the DPDD Parquet file directly:\n",
    "/global/cfs/cdirs/lsst/production/DC2_ImSim/Run2.2i/dpdd/dc2_object_run2.2i_dr6.parquet\n",
    "\n",
    "It's 42 GB.  Needs to be used in significantly-restricted column mode or with some Spark/DASK approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this Notebook is structured around keeping a list of indexes and using those indexes together with column names to desparately (and somewhat unsuccessfully) try to avoid Pandas making a copy or a large subset of the dataframe.  I think I've at least succeeded in making it not persist the temporary copies it still creates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Needed Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from numpy.lib import scimath as SM\n",
    "\n",
    "import astropy.units as u\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GCRCatalogs\n",
    "from GCR import GCRQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = 'viridis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Catalog and Subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could directly use the DPDD Parquet file:\n",
    "catalog_dirname = \"/global/cfs/cdirs/lsst/production/DC2_ImSim/Run2.2i/dpdd/\"\n",
    "catalog_basename = \"dc2_object_run2.2i_dr6.parquet\"\n",
    "catalog_file = os.path.join(catalog_dirname, catalog_basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_name = \"dc2_object_run2.2i_dr6a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_factor = 100\n",
    "restrict_to_tracts = None\n",
    "# restrict_to_tracts = [3640]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = ('u', 'g', 'r', 'i', 'z', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['ra', 'dec']\n",
    "columns += [f'mag_{f}' for f in filters]\n",
    "columns += [f'magerr_{f}' for f in filters]\n",
    "columns += [f'mag_{f}_cModel' for f in filters]\n",
    "columns += [f'magerr_{f}_cModel' for f in filters]\n",
    "columns += [f'I_flag']\n",
    "columns += [f'I_flag_{f}' for f in filters]\n",
    "# columns += [f'IxxPSF_{f}' for f in filters]\n",
    "# columns += [f'IxyPSF_{f}' for f in filters]\n",
    "# columns += [f'IyyPSF_{f}' for f in filters]\n",
    "columns += [f'Ixx_{f}' for f in filters]\n",
    "columns += [f'Ixy_{f}' for f in filters]\n",
    "columns += [f'Iyy_{f}' for f in filters]\n",
    "columns += [f'psf_fwhm_{f}' for f in filters]\n",
    "columns += ['good', 'extendedness', 'blendedness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are going to load 60 columns.\n",
      "For 520000 rows that should take 0.24 GB of memory\n"
     ]
    }
   ],
   "source": [
    "num_rows = 52000000 // sampling_factor\n",
    "MB_per_column_per_row = 512 / 64000000  # Based on estimates from previous runs.\n",
    "MB_per_column = num_rows * MB_per_column_per_row\n",
    "print(f'We are going to load {len(columns)} columns.')\n",
    "print(f'For {num_rows} rows that should take {(len(columns))*MB_per_column/1024:0.2f} GB of memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sampling_factor > 1:\n",
    "    arbitrary_number = 9230826780376522\n",
    "    remainder = arbitrary_number % sampling_factor\n",
    "    subsample = (lambda x: x % sampling_factor == remainder, 'objectId')\n",
    "else:\n",
    "    subsample = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select good detections:\n",
    "#  1. Marked as 'good' in catalog flags.\n",
    "#  2. SNR in given band > threshold\n",
    "#  3. In defined simulation range\n",
    "snr_threshold = 5\n",
    "snr_filter = 'i'\n",
    "\n",
    "# We want to do a SNR cut, but magerr is the thing already calculated\n",
    "# So we'll redefine our SNR in terms of magerr\n",
    "magerr_cut = (2.5 / np.log(10)) / snr_threshold\n",
    "snr_cut = f'magerr_{snr_filter} < {magerr_cut}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly read Parquet file:\n",
    "# You can define filters for the pyarrow.parquet backend.  See:\n",
    "# https://arrow.apache.org/docs/python/generated/pyarrow.parquet.ParquetDataset.html\n",
    "parquet_filters = []\n",
    "parquet_filters.append((f'magerr_{snr_filter}', '<', magerr_cut))\n",
    "parquet_filters.append(('good', '==', True))\n",
    "if restrict_to_tracts is not None:\n",
    "    parquet_filters.append(('tract', 'in', restrict_to_tracts))\n",
    "\n",
    "# But the allowed operator list is restricted to: =, ==, !=, <, >, <=, >=, in, not in\n",
    "# https://arrow.apache.org/docs/_modules/pyarrow/parquet.html#ParquetDataset\n",
    "\n",
    "# So we can't map the subsampling based on last digit of ObjectId like we do for GCR\n",
    "# We need to pass use_legacy_data=False to allow for filtering on any columns rather than columsn that are also partition keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_cuts = []\n",
    "quality_cuts.append(GCRQuery(snr_cut))\n",
    "quality_cuts.append(GCRQuery('good == True'))\n",
    "gcr_filters = [subsample] + quality_cuts\n",
    "\n",
    "config_overwrite = {'use_cache': False}\n",
    "if restrict_to_tracts is not None:\n",
    "    config_overwrite['tracts'] = restrict_to_tracts\n",
    "    \n",
    "cat = GCRCatalogs.load_catalog(catalog_name, config_overwrite=config_overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_from_dpdd_parquet = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that sampling_factor will not result in the same subsample for direct DPDD Parquet and the GCRCatalog subsample.\n",
    "if read_from_dpdd_parquet:\n",
    "    df = pd.read_parquet(catalog_file, columns=columns, use_legacy_data=False)\n",
    "    if sampling_factor > 1:\n",
    "        df = df.sample(frac=1/sampling_factor)\n",
    "else:\n",
    "    df = pd.DataFrame(cat.get_quantities(columns, filters=gcr_filters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Loaded {len(df)} objects.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix PSF definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if read_from_dpdd_parquet:\n",
    "    pixel_scale = 0.2\n",
    "    for filt in filters:\n",
    "        xx = df[f'IxxPSF_{filt}']\n",
    "        yy = df[f'IyyPSF_{filt}']\n",
    "        xy = df[f'IxyPSF_{filt}']\n",
    "        df[f'psf_fwhm_{filt}'] = pixel_scale * 2.355 * (xx * yy - xy * xy) ** 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if read_from_dpdd_parquet:\n",
    "    second_moment_psf_columns_to_drop = []\n",
    "    second_moment_psf_columns_to_drop.extend([f'IxxPSF_{filt}' for filt in filters])\n",
    "    second_moment_psf_columns_to_drop.extend([f'IyyPSF_{filt}' for filt in filters])\n",
    "    second_moment_psf_columns_to_drop.extend([f'IxyPSF_{filt}' for filt in filters])\n",
    "\n",
    "    # To drop columns, Pandas still creates a temporary new dataframe and then replaces it,\n",
    "    # so the 'inplace' is misleading about how it actually does things in memory\n",
    "    df.drop(second_moment_psf_columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good = df[\"good\"]\n",
    "good_idx, = np.where(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Loaded {len(good_idx)} good objects.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Density in RA, Dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DC2 Run 2.x WFD and DDF regions\n",
    "https://docs.google.com/document/d/18nNVImxGioQ3tcLFMRr67G_jpOzCIOdar9bjqChueQg/view\n",
    "https://github.com/LSSTDESC/DC2_visitList/blob/master/DC2visitGen/notebooks/DC2_Run2_regionCoords_WFD.ipynb\n",
    "\n",
    "| Location          | RA (degrees) | Dec (degrees) | RA (degrees) | Dec (degrees) |\n",
    "|:----------------- |:------------ |:------------- |:------------ |:------------- |\n",
    "| Region            | WFD          | WFD           | DDF          | DDF           |\n",
    "| Center            | 61.856114    | -35.79        | 53.125       | -28.100       |\n",
    "| North-East Corner | 71.462228    | -27.25        | 53.764       | -27.533       |\n",
    "| North-West Corner | 52.250000    | -27.25        | 52.486       | -27.533       |\n",
    "| South-West Corner | 49.917517    | -44.33        | 52.479       | -28.667       |\n",
    "| South-East Corner | 73.794710    | -44.33        | 53.771       | -28.667       |\n",
    "\n",
    "(Note that the order of the rows above is different than in the DC2 papers.  The order of the rows above goes around the perimeter in order.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc2_run2x_wfd = [[71.462228, -27.25], [52.250000, -27.25], [49.917517, -44.33], [73.794710, -44.33]]\n",
    "dc2_run2x_ddf = [[53.764, -27.533], [52.486, -27.533], [52.479, -28.667], [53.771, -28.667]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ra_dec(ra, dec, show_dc2_region=True, bins=100, cmin=10):\n",
    "    \"\"\"We're just doing this on a rectilinear grid.\n",
    "    We should do a projection, of course, but that distortion is tolerable in this space.\"\"\"\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "    plt.hist2d(ra, dec, bins=bins, cmin=cmin)\n",
    "    ax.invert_xaxis()  # Flip to East left\n",
    "    plt.xlabel('RA [deg]')\n",
    "    plt.ylabel('Dec [deg]')\n",
    "    plt.colorbar(shrink=0.5, label='objects / bin')\n",
    "\n",
    "    if show_dc2_region:\n",
    "        # This region isn't quite a polygon.  The sides should be curved.\n",
    "        wfd_region = Polygon(dc2_run2x_wfd, color='red', fill=False)\n",
    "        ddf_region = Polygon(dc2_run2x_ddf, color='orange', fill=False)\n",
    "        ax.add_patch(wfd_region)\n",
    "        ax.add_patch(ddf_region)\n",
    "\n",
    "        max_delta_ra = dc2_run2x_wfd[3][0] - dc2_run2x_wfd[2][0]\n",
    "        delta_dec = dc2_run2x_wfd[1][1] - dc2_run2x_wfd[3][1]\n",
    "        grow_buffer = 0.05\n",
    "        ax.set_xlim(dc2_run2x_wfd[3][0] + max_delta_ra * grow_buffer,\n",
    "                    dc2_run2x_wfd[2][0] - max_delta_ra * grow_buffer)\n",
    "        ax.set_ylim(dc2_run2x_wfd[3][1] - delta_dec * grow_buffer,\n",
    "                    dc2_run2x_wfd[1][1] + delta_dec * grow_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ra_dec(df.loc[good, 'ra'], df.loc[good, 'dec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall object density distribution looks good.  The purple edges are regions where the histgoram bin partially overlaps a tract edge.  Withouth perfect alignment, one should always expect some partial overlap, but that overlap amount will change.  So the overlap at the top of a row of tracts remains constant, but the edge overlap between the RA bounds of each tract will be different, so some are purple, some are blue, and some are green above.\n",
    "\n",
    "Notes:\n",
    "* We're missing the DDF region, which was specifically not included in this processing\n",
    "* There are also a few patches that failed within the main region.\n",
    "* There is an overall gradient N/S in object density, because we're plotting in rectilinear RA, Dec bins, which means that bins at the bottom in RA cover less area than those at the top.\n",
    "\n",
    "See the input visit coverage map here:\n",
    "https://github.com/LSSTDESC/ImageProcessingPipelines/issues/97#issuecomment-498303504\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_idx, = np.where(good & (df['extendedness'] == 0))\n",
    "galaxy_idx, = np.where(good & (df['extendedness'] > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total: {len(df)}, Good: {len(good_idx)}, Stars: {len(star_idx)}, Galaxies: {len(galaxy_idx)}')\n",
    "if read_from_dpdd_parquet:\n",
    "    print(f'For {catalog_file} with {sampling_factor}x subsample')\n",
    "else:\n",
    "    print(f'For {catalog_name} with {sampling_factor}x subsample')\n",
    "\n",
    "if restrict_to_tracts:\n",
    "    print(f'Tracts: ', restrict_to_tracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color-Color Diagrams and the Stellar Locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We refer to a file over in `tutorials/assets' for the stellar locus\n",
    "datafile_davenport = '../tutorials/assets/Davenport_2014_MNRAS_440_3430_table1.txt'\n",
    "\n",
    "def get_stellar_locus_davenport(color1='gmr', color2='rmi',\n",
    "                                datafile=datafile_davenport):\n",
    "    data = pd.read_table(datafile, sep='\\s+', header=1)\n",
    "    return data[color1], data[color2]\n",
    "\n",
    "    \n",
    "def plot_stellar_locus(color1='gmr', color2='rmi',\n",
    "                       color='blue', linestyle='--', linewidth=2.5,\n",
    "                       ax=None):\n",
    "    model_gmr, model_rmi = get_stellar_locus_davenport(color1, color2)\n",
    "    plot_kwargs = {'linestyle': linestyle, 'linewidth': linewidth, 'color': color,\n",
    "                   'scalex': False, 'scaley': False}\n",
    "    if not ax:\n",
    "        ax = fig.gca()\n",
    "\n",
    "    ax.plot(model_gmr, model_rmi, **plot_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_color_color(df, color1, color2, \n",
    "                     range1=(-1, +2), range2=(-1, +2), bins=101,\n",
    "                     cmin=10, cmap='gist_heat_r',\n",
    "                     vmin=None, vmax=None,\n",
    "                     ax=None, figsize=(4,4)):\n",
    "    \"\"\"Plot a color-color diagram.  Overlay stellar locus\"\"\"\n",
    "    band1, band2 = color1[0], color1[-1]\n",
    "    band3, band4 = color2[0], color2[-1]\n",
    "    H, xedges, yedges = np.histogram2d(\n",
    "        df[f'mag_{band1}'] - df[f'mag_{band2}'],\n",
    "        df[f'mag_{band3}'] - df[f'mag_{band4}'],\n",
    "        range=(range1, range2), bins=bins)\n",
    "        \n",
    "    zi = H.T\n",
    "    xi = (xedges[1:] + xedges[:-1])/2\n",
    "    yi = (yedges[1:] + yedges[:-1])/2\n",
    "\n",
    "    if not ax:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.gca()\n",
    "\n",
    "    # Only take elements with a minimum number of entries\n",
    "    zi = np.where(zi >= cmin, zi, np.nan)\n",
    "\n",
    "    im = ax.pcolormesh(xi, yi, zi, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    cf = ax.contour(xi, yi, zi)\n",
    "    ax.set_xlabel(f'{band1}-{band2}')\n",
    "    ax.set_ylabel(f'{band3}-{band4}')\n",
    "\n",
    "    try:\n",
    "        plot_stellar_locus(color1, color2, ax=ax)\n",
    "    except KeyError as e:\n",
    "        print(f\"Couldn't plot Stellar Locus model for {color1}, {color2}\")\n",
    "        \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_four_color_color(cat, vmin=0, vmax=50000):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(8, 6))\n",
    "\n",
    "    colors = ['umg', 'rmi', 'imz', 'zmy']\n",
    "    ref_color = 'gmr'\n",
    "    for ax, color in zip(axes.flat, colors):\n",
    "        try:\n",
    "            im = plot_color_color(cat, ref_color, color, ax=ax,\n",
    "                                 vmin=vmin, vmax=vmax)\n",
    "            ax.set_ylim(-1, +2)\n",
    "        except KeyError:\n",
    "            continue\n",
    "            \n",
    "    fig.colorbar(im)\n",
    "    plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_columns = [f\"mag_{filt}\" for filt in filters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_four_color_color(df.loc[good, mag_columns], vmax=len(good_idx)/1e3)\n",
    "plt.title(\"Good objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_four_color_color(df.loc[star_idx, mag_columns], vmax=len(star_idx)/1e3)\n",
    "plt.title(\"Stars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discrete islands in the data for stellar color-color plot -- most visible in `r-i` vs. `g-r` at g-r ~= 1.2 mag -- are due to the finite set of stellar models used for simulating M dwarfs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "Let's plot the galaxies on the same color-color plots\n",
    "\n",
    "Clearly one doesn't expect the galaxies to follow the stellar locus.  But including the stellar locus lines makes it easy to guide the eye between the stars-only and the galaxies-only plots.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_four_color_color(df.loc[galaxy_idx, mag_columns], vmax=len(galaxy_idx)/1e3)\n",
    "plt.title(\"Galaxies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions for further study:\n",
    "   1. Is there a better comparison sample for the stellar locus than the Davenport reference?\n",
    "   2. Why is the stellar locus in the Davenport 0.1--0.2 mag redder for the reddest stars than the observed data.  Are there different extinction assumptions (this should be a low-extinction region).  Are there different bandpasses used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Density Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mag(df, filt, good_idx, star_idx, galaxy_idx, log=True, range=(16, 28), ax=None, ):\n",
    "    if ax is None:\n",
    "        ax = fig.gca()\n",
    "    mag = f'mag_{filt}'\n",
    "    ax.hist([df.loc[good_idx, mag], df.loc[star_idx, mag], df.loc[galaxy_idx, mag]],\n",
    "            label=['good', 'star', 'galaxy'],\n",
    "            log=log,\n",
    "            range=range,\n",
    "            bins=np.linspace(*range, 100),\n",
    "            histtype='step')\n",
    "    ax.set_xlabel(filt)\n",
    "    ax.set_ylabel('objects / bin')\n",
    "    ax.set_xlim(range)\n",
    "    ax.set_ylim(bottom=10)\n",
    "    ax.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "for ax, filt in zip(axes.flat, filters):\n",
    "    plot_mag(df, filt, good_idx, star_idx, galaxy_idx, ax=ax, range=(16, 32))\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sharp cut in i-band is because that was the reference band for most detections.  The distributions in the other bands extend to 28th mag because many of the forced-photometry measurements are consistent with 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare number densities, we have to calculate the area covered by each catalog.\n",
    "We'll use Healpix through HealPy to pixelate the region and then count of the number of pixels with significant numbers of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_area(cat, threshold=0.25, nside=1024, verbose=False):\n",
    "    \"\"\"Calculate the area covered by a catalog with 'ra', 'dec'\n",
    "    \n",
    "    Parameters:\n",
    "    --\n",
    "    cat: DataFrame, dict-like with 'ra', 'dec', keys\n",
    "    threshold:  float\n",
    "        Fraction of median value required to count a pixel.\n",
    "    nside:  int\n",
    "        Healpix NSIDE.  NSIDE=1024 is ~12 sq arcmin/pixel, NSIDE=4096 is 0.74 sq. arcmin/pixel\n",
    "        Increasing nside will decrease calculated area as holes become better resolved \n",
    "        and relative Poisson fluctuations in number counts become more significant.\n",
    "    verbose:  bool\n",
    "        Print details on nside, number of significant pixels, and area/pixel.\n",
    "        \n",
    "    Returns:\n",
    "    --\n",
    "    area:  Astropy Quantity.\n",
    "    \"\"\"\n",
    "    import healpy as hp\n",
    "\n",
    "    indices = hp.ang2pix(nside, cat['ra'], cat['dec'], lonlat=True)\n",
    "    idx, counts = np.unique(indices, return_counts=True)\n",
    "    \n",
    "    # Take the 25% of the median value of the non-zero counts/pixel\n",
    "    threshold_counts = threshold * np.median(counts)\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Median {np.median(counts)} objects/pixel')\n",
    "        print(f'Only count pixels with more than {threshold_counts} objects')\n",
    "\n",
    "    significant_pixels, = np.where(counts > threshold_counts)\n",
    "    area_pixel = hp.nside2pixarea(nside, degrees=True) * u.deg**2\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Pixel size ~ {hp.nside2resol(nside, arcmin=True) * u.arcmin:0.2g}')\n",
    "        print(f'nside: {nside}, area/pixel: {area_pixel:0.4g}, num significant pixels: {len(significant_pixels)}')\n",
    "\n",
    "    area = len(significant_pixels) * area_pixel\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Total area: {area:0.7g}')\n",
    "    \n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_dc2 = calculate_area(df.loc[galaxy_idx, ['ra', 'dec']])\n",
    "print(f'DC2 Run 2.2i area: {area_dc2:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_den_dc2 = sampling_factor * len(galaxy_idx) / area_dc2\n",
    "\n",
    "# Change default expression to 1/arcmin**2\n",
    "num_den_dc2 = num_den_dc2.to(1/u.arcmin**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we plot the *normalized* i-band magnitude distributions in Run 2.2i and HSC.\n",
    "# They are normalized so we can focus on the shape of the distribution.\n",
    "# However, the legend indicates the total number density of galaxies selected with our magnitude cut,\n",
    "# which lets us find issues with the overall number density matching (or not).\n",
    "\n",
    "max_mag_i = 27\n",
    "plt.figure(figsize=(8, 8))\n",
    "nbins = 50\n",
    "mag_range = [20, max_mag_i]\n",
    "data_to_plot = df.loc[galaxy_idx, 'mag_i']\n",
    "labels_to_plot = [\n",
    "    f'Run 2.2i object catalog: {num_den_dc2.value:.1f} {num_den_dc2.unit:fits}',\n",
    "]\n",
    "plt.hist(data_to_plot, nbins, range=mag_range, histtype='step',\n",
    "         label=labels_to_plot, linewidth=2.0, density=True)\n",
    "    \n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('i-band magnitude')\n",
    "plt.ylabel('normalized distribution')\n",
    "plt.yscale('log')\n",
    "plt.savefig('dc2_object_run2.2i_galaxy_counts.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magnitude Error vs. Magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The magnitude uncertainties come directly from the poisson estimates of the flux measurements.  By construction they will follow smooth curves.  We here confirm that they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mag_magerr(df, band, ax=None, range=(16, 28), magerr_limit=0.25, vmin=100):\n",
    "    # vmin=100 is reasonable for a ~50 million objects\n",
    "    # If testing with one tract or a large subsampling factor, choose a smaller vmin.\n",
    "    # Restrict to reasonable range\n",
    "    mag_col, magerr_col = f'mag_{band}', f'magerr_{band}'\n",
    "    good = df[df[magerr_col] < magerr_limit]\n",
    "\n",
    "    ax.hexbin(good[mag_col], good[magerr_col], vmin=vmin)\n",
    "    ax.set_xlabel(band)\n",
    "    ax.set_ylabel(f'{band} err');\n",
    "    ax.set_ylim(0, magerr_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "for ax, filt in zip(axes.flat, filters):\n",
    "    mag_col, magerr_col = f'mag_{filt}', f'magerr_{filt}'\n",
    "    plot_mag_magerr(df.loc[galaxy_idx, [mag_col, magerr_col]], filt, ax=ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "for ax, filt in zip(axes.flat, filters):\n",
    "    mag_col, magerr_col = f'mag_{filt}', f'magerr_{filt}'\n",
    "    plot_mag_magerr(df.loc[star_idx, [mag_col, magerr_col]], filt, ax=ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blendedness\n",
    "\n",
    "Blendedness is a measure of how much the identified flux from an object is affected by overlapping from other objects.\n",
    "\n",
    "See Bosch et al., 2018, Section 4.9.11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, = np.where(np.isfinite(df.loc[good_idx, 'blendedness']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{100 * len(w)/len(good_idx):0.1f}% of objects have finite blendedness measurements.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question for futher study:  What happened to yield non-finite blendedness measurements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_blendedness = good & np.isfinite(df['blendedness'])\n",
    "plt.hexbin(df.loc[good_blendedness, 'mag_i'], df.loc[good_blendedness, 'blendedness'],\n",
    "          bins='log', vmin=10);\n",
    "plt.xlabel('i')\n",
    "plt.ylabel('blendedness');\n",
    "plt.colorbar(label='objects / bin');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extendedness\n",
    " \n",
    "Extendedness is essentially star/galaxy separation based purely on morphology in the main detected reference band (which is `i` for most Objects).\n",
    "\n",
    "Extendedness a binary property in the catalog, so it's either 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hexbin(df.loc[good_idx, 'mag_i'], df.loc[good_idx, 'extendedness'],\n",
    "           extent=(14, 26, -0.1, +1.1),\n",
    "           bins='log', vmin=10);\n",
    "plt.xlabel('i')\n",
    "plt.ylabel('extendedness');\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.text(19, 0.1, \"STARS\", fontdict={'fontsize': 24}, color='orange')\n",
    "plt.text(19, 0.8, \"GALAXIES\", fontdict={'fontsize': 24}, color='orange')\n",
    "plt.colorbar(label='objects / bin');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the first plot above made extendedness look like a simple binary property, the truth is more complicated.\n",
    "\n",
    "As galaxies get smaller in angular size and lower in signal-to-noise ratio, it becomes harder to clearly distinguish stars from galaxies.\n",
    "\n",
    "Extendedness is based off of the difference between the point-source model and extended model brightness.  Specifically objects with `mag_psf - mag_cmodel > 0.164` mag are labeled with `extendedness=1` (i.e., galaxies).\n",
    "\n",
    "See Bosch et al. 2018, Section 4.9.10 for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axvline(0.0164, 0.4, 1, color='red', linestyle='--',\n",
    "           label=r'0.0164 $\\Delta$mag cut')  # psf-cModel mag cut from Bosch et al. 2018.\n",
    "\n",
    "plt.hist([df.loc[good_idx, 'mag_i'] - df.loc[good_idx, 'mag_i_cModel'],\n",
    "         df.loc[star_idx, 'mag_i'] - df.loc[star_idx, 'mag_i_cModel'],\n",
    "         df.loc[galaxy_idx, 'mag_i'] - df.loc[galaxy_idx, 'mag_i_cModel']],\n",
    "         label=['Good', 'Stars', 'Galaxies'],\n",
    "         bins=np.linspace(-0.1, 0.1, 201),\n",
    "         histtype='step')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('mag_i[_psf] - mag_i_CModel');\n",
    "plt.ylabel('objects / bin')\n",
    "\n",
    "plt.text(0.25, 0.04, \"STARS\", transform=plt.gca().transAxes, fontdict={'fontsize': 24}, color='orange');\n",
    "plt.text(0.65, 0.04, \"GALAXIES\", transform=plt.gca().transAxes, fontdict={'fontsize': 24}, color='orange')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hexbin(df.loc[good_idx, 'mag_i'], df.loc[good_idx, 'mag_i'] - df.loc[good_idx, 'mag_i_cModel'],\n",
    "           extent=(14, 26, -0.75, +2.5),\n",
    "           bins='log');\n",
    "plt.xlabel('i')\n",
    "plt.ylabel('mag_i[_psf] - mag_i_CModel');\n",
    "plt.text(14.5, -0.5, \"STARS\", fontdict={'fontsize': 24}, color='orange')\n",
    "plt.text(18, 2, \"GALAXIES\", fontdict={'fontsize': 24}, color='orange')\n",
    "plt.colorbar(label='objects / bin');\n",
    "\n",
    "plt.axhline(0.0164, 0.92, 1.0, color='red', linestyle='--')\n",
    "plt.axhline(0.0164, 0, 0.1, color='red', linestyle='--',\n",
    "            label=r'0.0164 $\\Delta$mag cut');  # psf-cModel mag cut from Bosch et al. 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can zoom in a little to see how the fixed 0.0164 mag cut works at the low SNR limit.  Specifically at mag 24, we're starting to run out of stars and most things are galaxies.  But that's a population prior, it's not something visible using just morphology information.\n",
    "\n",
    "You can see the effect of lower SNR measurements as the horizontal line at $\\Delta$mag=0 puff up due to increased uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hexbin(df.loc[good_idx, 'mag_i'], df.loc[good_idx, 'mag_i'] - df.loc[good_idx, 'mag_i_cModel'],\n",
    "           extent=(22, 25.5, -0.1, +0.5),\n",
    "           bins='log');\n",
    "plt.xlabel('i')\n",
    "plt.ylabel('mag_i[_psf] - mag_i_CModel');\n",
    "plt.colorbar(label='objects / bin');\n",
    "\n",
    "plt.axhline(0.0164, 0, 1, color='red', linestyle='--',\n",
    "            label=r'0.0164 $\\Delta$mag cut');  # psf-cModel mag cut from Bosch et al. 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we add in color information, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hexbin(df.loc[good_idx, 'mag_g'] - df.loc[good_idx, 'mag_r'], df.loc[good_idx, 'mag_i'] - df.loc[good_idx, 'mag_i_cModel'],\n",
    "           extent=(-2, +3, -0.5, +5),\n",
    "           bins='log');\n",
    "plt.xlabel('g-r')\n",
    "plt.ylabel('mag_i[_psf] - mag_i_CModel');\n",
    "# plt.text(14.5, 0.3, \"STARS\", fontdict={'fontsize': 24}, color='orange')\n",
    "# plt.text(18, 2, \"GALAXIES\", fontdict={'fontsize': 24}, color='orange')\n",
    "plt.colorbar(label='objects / bin');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([df.loc[galaxy_idx, 'mag_g'] - df.loc[galaxy_idx, 'mag_r'], df.loc[star_idx, 'mag_g'] - df.loc[star_idx, 'mag_r']],\n",
    "        label=['galaxies', 'stars'], histtype='step',\n",
    "        bins=np.linspace(-5, +5, 501));\n",
    "plt.xlabel('g-r')\n",
    "plt.ylabel('objects / bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hexbin(df.loc[star_idx, 'mag_g'] - df.loc[star_idx, 'mag_r'], df.loc[star_idx, 'mag_i'] - df.loc[star_idx, 'mag_i_cModel'],\n",
    "           extent=(-2, +3, -0.5, +5),\n",
    "           bins='log');\n",
    "plt.xlabel('g-r')\n",
    "plt.ylabel('mag_i[_psf] - mag_i_CModel');\n",
    "# plt.text(14.5, 0.3, \"STARS\", fontdict={'fontsize': 24}, color='orange')\n",
    "# plt.text(18, 2, \"GALAXIES\", fontdict={'fontsize': 24}, color='orange')\n",
    "plt.colorbar(label='objects / bin');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape Parameters\n",
    "\n",
    "Ixx, Iyy, Ixy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shape(df, filt, good_idx, star_idx, galaxy_idx, ax=None, legend=True):\n",
    "    if not ax:\n",
    "        ax = fig.gca()\n",
    "\n",
    "    names = ['good', 'star', 'galaxy']\n",
    "    colors = ['blue', 'orange', 'green']\n",
    "    hist_kwargs = {'color': colors, 'log': True,\n",
    "             'bins': np.logspace(-1, 1.5, 100),\n",
    "             'range': (0, 50),\n",
    "             'histtype': 'step'}\n",
    "    for prefix, ls in (('Ixx', '-'), ('Iyy', '--'), ('Ixy', ':')):\n",
    "        field = f'{prefix}_{filt}'\n",
    "        labels = [f'{prefix} {name}' for name in names]\n",
    "        ax.hist([df.loc[good_idx, field], df.loc[star_idx, field], df.loc[galaxy_idx, field]],\n",
    "                label=labels,\n",
    "                linestyle=ls,\n",
    "                **hist_kwargs)\n",
    "\n",
    "    ax.set_ylim(100, ax.get_ylim()[1])\n",
    "    \n",
    "    ax.set_xlabel(f'{filt}-band Moments: Ixx, Iyy, Ixy [pixels^2]')\n",
    "    ax.set_ylabel('objects / bin')\n",
    "    if legend:\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "legend = True\n",
    "for ax, filt in zip(axes.flat, filters):\n",
    "    plot_shape(df, filt, good_idx, star_idx, galaxy_idx, ax=ax, legend=legend)\n",
    "    legend = False\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stars (orange) are concentrated at low values of the source moments.\n",
    "\n",
    "Would be interesting to\n",
    "1. Look by magnitude or SNR to undersatnd the longer tail.  Are these galaxies mis-classified as stars, or are these noise sources?\n",
    "2. Distribution of ellipticity (see validate_drp to type this right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipticity(I_xx, I_xy, I_yy):\n",
    "    \"\"\"Calculate ellipticity from second moments.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    I_xx : float or numpy.array\n",
    "    I_xy : float or numpy.array\n",
    "    I_yy : float or numpy.array\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    e, e1, e2 : (float, float, float) or (numpy.array, numpy.array, numpy.array)\n",
    "        Complex ellipticity, real component, imaginary component\n",
    "        \n",
    "    Copied from https://github.com/lsst/validate_drp/python/lsst/validate/drp/util.py\n",
    "    \"\"\"\n",
    "    e = (I_xx - I_yy + 2j*I_xy) / (I_xx + I_yy + 2*SM.sqrt(I_xx*I_yy - I_xy*2))\n",
    "    e1 = np.real(e)\n",
    "    e2 = np.imag(e)\n",
    "    return e, e1, e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ellipticity(df, filt, good_idx, star_idx, galaxie_idx, ax=None, legend=True):\n",
    "    if not ax:\n",
    "        ax = fig.gca()\n",
    "\n",
    "    names = ['good', 'star', 'galaxy']\n",
    "    colors = ['blue', 'orange', 'green']\n",
    "    hist_kwargs = {'color': colors, 'log': True,\n",
    "             'bins': np.logspace(-1, 1.5, 100),\n",
    "             'range': (0, 5),\n",
    "             'histtype': 'step'}\n",
    "    for prefix, ls in (('e', '-'), ('e1', '--'), ('e2', ':')):\n",
    "        field = f'{prefix}_{filt}'\n",
    "        labels = [f'{prefix} {name}' for name in names]\n",
    "        ax.hist([df.loc[good_idx, field], df.loc[star_idx, field], df.loc[galaxy_idx, field]],\n",
    "                label=labels,\n",
    "                linestyle=ls,\n",
    "                **hist_kwargs)\n",
    "\n",
    "    ax.set_xlim(0, 20)\n",
    "    ax.set_ylim(10)\n",
    "    \n",
    "    ax.set_xlabel(f'{filt}-band ellipticity')\n",
    "    ax.set_ylabel('objects / bin')\n",
    "    if legend:\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filt in filters:\n",
    "    df[f'e_{filt}'], df[f'e1_{filt}'], df[f'e2_{filt}'] = \\\n",
    "    ellipticity(df[f'Ixx_{filt}'], df[f'Ixy_{filt}'], df[f'Iyy_{filt}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "legend = True\n",
    "for ax, filt in zip(axes.flat, filters):\n",
    "    plot_ellipticity(df, filt, good_idx, star_idx, galaxy_idx, ax=ax, legend=legend)\n",
    "    legend = False\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FWHM of the PSF\n",
    "At the location of the catalog objects.\n",
    "\n",
    "The Object Table stores the shape parameters of the PSF model as evaluated at the location of the object.\n",
    "\n",
    "This is not the same as, but is certainly related to, the distribution of effective seeing in the individual images that made up the coadd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_psf_fwhm(df, filters=filters,\n",
    "                 colors=('purple', 'blue', 'green', 'orange', 'red', 'brown')):\n",
    "    for filt, color in zip(filters, colors):\n",
    "        psf_fwhm = np.array(df.loc[good_idx, f'psf_fwhm_{filt}'])\n",
    "        w, = np.where(np.isfinite(psf_fwhm) & (psf_fwhm < 3))\n",
    "        sns.distplot(psf_fwhm[w], label=filt, color=color)\n",
    "    plt.xlabel('PSF FWHM [arcsec]')\n",
    "    plt.ylabel('normalized object density')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_psf_fwhm(\n",
    "    df,\n",
    "    filters,\n",
    "    colors=(\"purple\", \"blue\", \"green\", \"orange\", \"red\", \"brown\"),\n",
    "    max_psf_fwhm=1.5,\n",
    "    plotname=None,\n",
    "):\n",
    "    bins = np.linspace(0, max_psf_fwhm, 201)\n",
    "    for filt, color in zip(filters, colors):\n",
    "        psf_fwhm = df[f\"psf_fwhm_{filt}\"].to_numpy()\n",
    "        (w,) = np.where(np.isfinite(psf_fwhm) & (psf_fwhm < max_psf_fwhm))\n",
    "        plt.hist(psf_fwhm[w], label=filt, color=color, histtype='step',\n",
    "                bins=bins)\n",
    "    plt.xlabel(\"PSF FWHM [arcsec]\")\n",
    "    plt.ylabel(\"Objects/bin\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if plotname is not None:\n",
    "        plt.savefig(plotname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_fwhm_filters = [f\"psf_fwhm_{filt}\" for filt in filters]\n",
    "plot_psf_fwhm(df.loc[good_idx, psf_fwhm_filters], filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the PSF model at the location of the objects on the coadd."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
