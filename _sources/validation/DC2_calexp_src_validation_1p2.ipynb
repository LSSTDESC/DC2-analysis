{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation tests for DC2 1.2i/p single visit catalogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** Javier SÃ¡nchez\n",
    "\n",
    "**Date last run:** Apr-21-2019\n",
    "\n",
    "**Goals:** Make astrometry and photometry quality checks on 1.2i/p single-epoch data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the plots in this notebook can be made with 1.2p as well. You just have to change\n",
    "\n",
    "`gc_data = SingleVisitCatalog(repo=data_imsim, filter_band='r', visit=197425, detector=None)`\n",
    "\n",
    "To:\n",
    "\n",
    "`gc_data = SingleVisitCatalog(repo=data_phosim, filter_band='r', visit=197425, detector=None)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Note ** Temporary fix while GCRCatalogs is updated..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/global/homes/j/jsanch87/gcr-catalogs/')\n",
    "import GCRCatalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GCR\n",
    "#import GCRCatalogs\n",
    "import healpy as hp\n",
    "import pandas as pd\n",
    "from scipy.stats import binned_statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GCRCatalogs` contains a wrapper of the Butler in the `SingleVisitCatalog` class that is very convenient to query all detectors for a single visit or all visits of a given filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GCRCatalogs.butler_interface import SingleVisitCatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use sklearn to build the catalog matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the directory where the 1.2i data calexps live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imsim = '/global/cscratch1/sd/desc/DC2/data/Run1.2i_globus_in2p3_20181217/w_2018_39/rerun/281118'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_phosim = '/global/cscratch1/sd/desc/DC2/data/Run1.2p_v4/w_2018_39/rerun/calexp-v4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the columns that we are going to use in our validation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['coord_ra', # ra coordinate (in radians)\n",
    "           'coord_dec', # dec coordinate (in radians)\n",
    "           'calib_photometry_used', # Has this object been used for photometric calibrations?\n",
    "           'calib_astrometry_used', # Has this object been used for astrometric calibrations?\n",
    "           'base_ClassificationExtendedness_value', # This is a basic star/galaxy separation flag more on Bosch et al 2018\n",
    "           'ext_shapeHSM_HsmShapeRegauss_e1', # e1 using GalSim's HSM\n",
    "           'ext_shapeHSM_HsmShapeRegauss_e2', # e2 using GalSim's HSM\n",
    "           'base_SdssShape_xx', # xx moment using SDSS algorithm\n",
    "           'base_SdssShape_xy', # xy moment using SDSS algorithm\n",
    "           'base_SdssShape_yy', # yy moment using SDSS algorithm\n",
    "           'base_SdssShape_psf_xx', # xx moment of the PSF in the position of this object using SDSS algorithm\n",
    "           'base_SdssShape_psf_xy', # xy as above\n",
    "           'base_SdssShape_psf_yy', # yy as above\n",
    "           'base_PsfFlux_instFlux', # PSF-flux\n",
    "           'base_PsfFlux_instFluxErr', # PSF-flux error\n",
    "           'ext_photometryKron_KronFlux_instFlux', # Kron flux\n",
    "           'ext_photometryKron_KronFlux_instFluxErr', # Kron flux uncertainty\n",
    "           'ext_photometryKron_KronFlux_mag', # Kron magnitude\n",
    "           'ext_photometryKron_KronFlux_magErr', # Kron magnitude error\n",
    "           'base_PsfFlux_mag', # magnitude computed in a PSF magnitude (derived from base_PsfFlux_instFlux with the corresponding zeropoint)\n",
    "           'base_PsfFlux_magErr', # corresponding error to the above magnitude\n",
    "           'ra', # We are going to add RA in degrees\n",
    "           'dec' # We are going to add Dec in degrees\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we instantiate a galaxy catalog of the class `SingleVisitCatalog` from `gcr-catalogs`. This class allows for getting all single visits for a given filter. If you further specify the visit number, it will query all detectors for you. Finally, if you want to query a given detector, you can specify it via the detector option (the way to specify it is using the detector number rather than the typical sensor/raft). We choose visit 197425."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_data = SingleVisitCatalog(repo=data_imsim, filter_band='r', visit=197425, detector=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_data.add_derived_quantity('ra', np.degrees, 'coord_ra')\n",
    "gc_data.add_derived_quantity('dec', np.degrees, 'coord_dec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we also get the corresponding truth catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gc = GCRCatalogs.load_catalog('dc2_truth_run1.2_static')\n",
    "gc = GCRCatalogs.load_catalog('dc2_reference_run1.2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the quantities that these catalogs contain by listing their quantities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.list_all_quantities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load position and magnitudes from the benchmark catalog(s). Since it is unlikely that in a single visit we detect objects fainter than $r = 27$ we will filter them out so the query is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to create some extra columns to mix and match the reference and true catalogs\n",
    "gc.add_derived_quantity('star', np.logical_not, 'is_resolved')\n",
    "for band in 'ugrizy':\n",
    "    gc.add_derived_quantity('mag_true_%s' % band, lambda x: x, 'mag_%s_lsst' % band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take out `is_resolved` and `star` if using the truth catalog!\n",
    "data = gc.get_quantities(['ra','dec','mag_true_r','object_id','is_resolved', 'star'], filters=['mag_true_r < 27'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to load 189 sensor-visits using the butler. We just choose a subset of the columns, you can check which columns are available in the catalog using `gc_data.list_all_native_quantities()` and `gc_data.list_all_quantities()`.\n",
    "\n",
    "The catalogs contain the parent objects (before deblending) and the children object (after deblending), thus, it is important to filter out the objects with `deblend_nChild!=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_im = gc_data.get_quantities(columns, filters=['deblend_nChild == 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our data! (we plot only 10% of the data points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_im['ra'][::10],data_im['dec'][::10],s=0.01)\n",
    "plt.xlabel('RA [deg]')\n",
    "plt.ylabel('DEC [deg]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create a map with the detected objects so we discard  objects in the truth catalog that lie outside of the area that we observe. \n",
    "This is just an approximation but it should be enough for this tutorial. Ideally, we would use the WCS of each sensor/single-visit and select objects in the truth catalog that lie within the boundaries of each sensor/visit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import healpy as hp\n",
    "pixnums = hp.ang2pix(4096, data_im['ra'], data_im['dec'], lonlat=True)\n",
    "pixnums_true = hp.ang2pix(4096, data['ra'], data['dec'], lonlat=True)\n",
    "in_footprint = np.in1d(pixnums_true, np.unique(pixnums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only use objects in the true catalog that lie within the FOV \n",
    "ra_true = data['ra'][in_footprint]\n",
    "dec_true = data['dec'][in_footprint]\n",
    "mag_true = data['mag_true_r'][in_footprint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded the input and output catalogs, we need to relate them. We check the neighbors within a certain radius and choose the closest match in magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_closest_mag_1band(ra_data,dec_data,mag_data,\n",
    "                              ra_true,dec_true,mag_true,true_id,\n",
    "                              rmax=3,max_deltamag=1.):\n",
    "    \"\"\"\n",
    "    Function to return the closest match in magnitude within a user-defined radius within certain\n",
    "    magnitude difference.\n",
    "    \n",
    "    ***Caveats***: This method uses small angle approximation sin(theta)\n",
    "    ~ theta for the declination axis. This should be fine to find the closest\n",
    "    neighbor. This method does not use any weighting.\n",
    "    \n",
    "    Args:\n",
    "    -----\n",
    "    \n",
    "    ra_data: Right ascension of the measured objects (degrees).\n",
    "    dec_data: Declination of the measured objects (degrees).\n",
    "    mag_data: Measured magnitude of the objects.\n",
    "    ra_true: Right ascension of the true catalog (degrees).\n",
    "    dec_true: Declination of the true catalog (degrees).\n",
    "    mag_true: True magnitude of the true catalog.\n",
    "    true_id: Array of IDs in the true catalog.\n",
    "    rmax: Maximum distance in number of pixels to perform the query.\n",
    "    max_deltamag: Maximum magnitude difference for the match to be good.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    \n",
    "    dist: Distance to the closest neighbor in the true catalog. If inputs are\n",
    "    in degrees, the returned distance is in arcseconds.\n",
    "    true_id: ID in the true catalog for the closest match.\n",
    "    matched: True if matched, False if not matched.\n",
    "    \"\"\"\n",
    "    X = np.zeros((len(ra_true),2))\n",
    "    X[:,0] = ra_true\n",
    "    X[:,1] = dec_true\n",
    "    tree = KDTree(X,metric='euclidean')\n",
    "    Y = np.zeros((len(ra_data),2))\n",
    "    Y[:,0] = ra_data\n",
    "    Y[:,1] = dec_data\n",
    "    ind,dist= tree.query_radius(Y,r=rmax*0.2/3600,return_distance=True) # 0.2/3600 -> Pixel scale in arcseconds\n",
    "    matched = np.zeros(len(ind),dtype=bool)\n",
    "    ids = np.zeros(len(ind),dtype=true_id.dtype)\n",
    "    dist_out = np.zeros(len(ind))\n",
    "    for i, ilist in enumerate(ind):\n",
    "        if len(ilist)>0:\n",
    "            dmag = np.fabs(mag_true[ilist]-mag_data[i])\n",
    "            good_ind = np.argmin(dmag)\n",
    "            ids[i]=true_id[ilist[good_ind]]\n",
    "            dist_out[i]=dist[i][good_ind]\n",
    "            if np.min(dmag)<max_deltamag:\n",
    "                matched[i]=True\n",
    "            else:\n",
    "                matched[i]=False\n",
    "        else:\n",
    "            ids[i]=-99\n",
    "            matched[i]=False\n",
    "            dist_out[i]=-99.\n",
    "    return dist_out*3600., ids,matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd, ind_mag, matched = spatial_closest_mag_1band(data_im['ra'],\n",
    "                                                 data_im['dec'],\n",
    "                                                 data_im['ext_photometryKron_KronFlux_mag'],\n",
    "                                                 ra_true,\n",
    "                                                 dec_true,\n",
    "                                                 mag_true,\n",
    "                                                 np.arange(len(ra_true)),\n",
    "                                                 rmax=5,max_deltamag=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `calexps` contain some objects used for the photometric calibration. We are going to check the photometric residuals in these objects (`'calib_photometry_used'==True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isphoto = data_im['calib_photometry_used']\n",
    "mag_psf = data_im['base_PsfFlux_mag']\n",
    "data_mask = (matched) & (isphoto) & (data['star'][in_footprint][ind_mag]) # We want objects used for photometric calibration matched to stars\n",
    "plt.hist(mag_psf[data_mask] - mag_true[ind_mag][data_mask],\n",
    "        range=(-0.1,0.1),bins=100, histtype='step',label='stars')\n",
    "plt.xlabel('mag$_{PSF}$-mag$_{true}$',fontsize=14)\n",
    "plt.ylabel('Number of objects',fontsize=14)\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same happens for astrometry. We check the astrometric residuals for objects that have `'calib_astrometry_used'==True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isastro = data_im['calib_astrometry_used']\n",
    "data_mask = (matched) & (isastro) & (data['star'][in_footprint][ind_mag]) # We want objects used for astrometric calibration and matched to stars\n",
    "plt.hist(3600000*np.cos(data_im['coord_dec'][data_mask])*(np.degrees(data_im['coord_ra'])[data_mask]\n",
    "                  -ra_true[ind_mag][data_mask]),range=(-200,200),bins=200, histtype='step',label='RA stars')\n",
    "plt.hist(3600000*(np.degrees(data_im['coord_dec'])[data_mask]\n",
    "                  -dec_true[ind_mag][data_mask]),range=(-200,200),bins=200, histtype='step',label='DEC stars')\n",
    "plt.xlim(-30,30)\n",
    "plt.xlabel(r'$\\Delta X $ [mas]',fontsize=14)\n",
    "plt.ylabel('Number of objects',fontsize=14)\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to check the photometry for all detected objects matched to stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_mag = (~np.isnan(mag_psf)) & (matched) & (data['star'][in_footprint][ind_mag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_true = (data['star'][in_footprint]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_mag = data_im['base_PsfFlux_mag'][mask_mag]-mag_true[ind_mag][mask_mag] # We check the magnitude difference\n",
    "\n",
    "mean_im, be, _ = binned_statistic(mag_true[ind_mag][mask_mag], delta_mag, range=(10,30), bins=50, statistic='median')\n",
    "std_im, be, _ = binned_statistic(mag_true[ind_mag][mask_mag], delta_mag ,range=(10,30), bins=50, statistic='std')\n",
    "n_im, be, _ = binned_statistic(mag_true[ind_mag][mask_mag], delta_mag, range=(10,30), bins=50, statistic='count')\n",
    "n_true, be, _ = binned_statistic(mag_true[good_true], mag_true[good_true], range=(10,30), bins=50, statistic='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(0.5*be[1:]+0.5*be[:-1], mean_im,std_im/np.sqrt(n_im), fmt='o', color='red')\n",
    "plt.hexbin(mag_true[ind_mag][mask_mag], delta_mag, gridsize=200, extent=[14,26,-0.5,0.5])\n",
    "plt.xlabel('mag$_{true}$', fontsize=16)\n",
    "plt.ylabel('mag$_{PSF}$-mag$_{true}$', fontsize=16)\n",
    "plt.colorbar(label='Objects/bin')\n",
    "plt.grid()\n",
    "plt.ylim(-0.1,0.1)\n",
    "plt.xlim(14,26);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to check the sources' sizes as a function of their magnitude and look for the presence of brighter-fatter effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = (data_im['base_SdssShape_xx']+data_im['base_SdssShape_yy'])*0.2**2 # Trace of the second order moments in arcseconds^2 (that's why we multiply times 0.2)\n",
    "mean_im_t, be, _ = binned_statistic(mag_true[ind_mag][mask_mag], T[mask_mag], range=(10,30), bins=50, statistic='median')\n",
    "std_im_t, be, _ = binned_statistic(mag_true[ind_mag][mask_mag], T[mask_mag], range=(10,30), bins=50, statistic='std')\n",
    "n_im_t, be, _ = binned_statistic(mag_true[ind_mag][mask_mag], T[mask_mag], range=(10,30), bins=50, statistic='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(mag_true[ind_mag][mask_mag], T[mask_mag], c='b', s=0.4, alpha=0.2, label='stars')\n",
    "# Let's only plot 10% of the galaxies\n",
    "plt.scatter(mag_true[ind_mag][~mask_mag][::10],T[~mask_mag][::10], c='r', s=0.4, alpha=0.2, label='galaxies')\n",
    "plt.errorbar(0.5*be[1:]+0.5*be[:-1], mean_im_t, std_im_t/np.sqrt(n_im_t), fmt='o', c='orange', label='stars median')\n",
    "plt.ylabel('$T$ [arcsec$^{2}$]',fontsize=16)\n",
    "plt.xlabel('mag$_{r,true}$',fontsize=16)\n",
    "plt.grid()\n",
    "plt.ylim(0.,1.)\n",
    "plt.xlim(14,24)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = 0.5*(be[1:]+be[:-1])\n",
    "plt.errorbar(bc,mean_im_t-np.nanmean(mean_im_t[(bc>20) & (bc<22)]),std_im_t/np.sqrt(n_im_t),fmt='o')\n",
    "plt.ylabel(r'$\\Delta T$ [arcsec$^{2}$]',fontsize=16)\n",
    "plt.xlabel('mag$_{r,true}$',fontsize=16)\n",
    "plt.grid()\n",
    "plt.ylim(-0.01,0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see the Brighter-fatter effect!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very useful QA plot is to check the detection efficiency for stars as a function of magnitude.\n",
    "\n",
    "**Note:** We compare the number of detected/matched stars with the number of input objects in our selection, i.e., it depends on how we select the objects in the truth catalog that are in the footprint. For accurate results, we need to check the WCS of each calexp or use very high resolution masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(0.5*(be[1:]+be[:-1]),1.0*n_im/n_true,np.sqrt(n_im+n_true)/n_true,fmt='o')\n",
    "plt.xlabel('mag$_{true}$',fontsize=12)\n",
    "plt.ylabel('Detection efficiency (stars)',fontsize=12)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful QA plot is to construct a depth map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depth_map(ra, dec, mags, snr, nside=128, min_snr=4, max_snr=6):\n",
    "    \"\"\" Routine to quickly compute the depth given position, magnitude and SNR\n",
    "    \n",
    "    Args:\n",
    "    -----\n",
    "    ra: ndarray (float),\n",
    "        RA of the detected objects in degrees\n",
    "    dec: ndarray (float),\n",
    "        Dec of the detected objects in degrees\n",
    "    mags: ndarray (float),\n",
    "        Magnitude of the detected objects \n",
    "    snr: ndarray (float).\n",
    "        Array containing the SNR of the detected objects\n",
    "    \n",
    "    \"\"\"\n",
    "    # Filter NaNs and select objects in the range of SNR that we care about to speed things up\n",
    "    good = (~np.isnan(ra)) & (~np.isnan(dec)) & (snr >= min_snr) & (snr <= max_snr) \n",
    "    pix_nums = hp.ang2pix(nside,ra[good],dec[good], lonlat=True)\n",
    "    map_out = np.zeros(12*nside**2)\n",
    "    for px in np.unique(pix_nums):\n",
    "        mask = px==pix_nums\n",
    "        if np.count_nonzero(mask)>0:\n",
    "            map_out[px]=np.nanmedian(mags[good][mask]) \n",
    "        else:\n",
    "            map_out[px]=0.\n",
    "    return map_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hp_map(ra,dec,nside=128):\n",
    "    good = (~np.isnan(ra)) & (~np.isnan(dec))\n",
    "    pix_nums = hp.ang2pix(nside,ra[good],dec[good], lonlat=True)\n",
    "    pix_counts = np.bincount(pix_nums,minlength=12*nside**2)\n",
    "    return pix_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_array = (data_im['base_PsfFlux_instFlux']/ data_im['base_PsfFlux_instFluxErr'])[~np.isnan(data_im['base_PsfFlux_mag'])]\n",
    "test_map = get_depth_map(np.degrees(data_im['coord_ra'])[~np.isnan(data_im['base_PsfFlux_mag'])],\n",
    "                         np.degrees(data_im['coord_dec'])[~np.isnan(data_im['base_PsfFlux_mag'])],\n",
    "                         data_im['base_PsfFlux_mag'][~np.isnan(data_im['base_PsfFlux_mag'])],\n",
    "                         snr_array,\n",
    "                         nside=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the spatial distribution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.gnomview(test_map, rot=(55.7, -30.3), title='Depth', reso=1.3, min=23, max=25, unit=r'5-$\\sigma$ depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the overall 1D distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(test_map[test_map>0],range=(22,28),bins=100, histtype='step')\n",
    "plt.xlabel(r'5-$\\sigma$ depth', fontsize=16)\n",
    "plt.xlim(23, 25)\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-stack",
   "language": "python",
   "name": "desc-stack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
