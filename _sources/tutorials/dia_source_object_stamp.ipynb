{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIA Analysis: Source, Object, and Postage Stamps for Run 1.2p Test\n",
    "Michael Wood-Vasey\n",
    "Last Verified to Run: 2019-07-12\n",
    "\n",
    "After completing this Notebook, the users will be able to\n",
    "1. Plot statistics of DIAObject and DIASource tables.\n",
    "2. Select and plot lightcurve of DIA Object.\n",
    "3. Locate that DIA Object in the truth catalog of input variables\n",
    "4. Describe how DIASource and DIAObject tables are constructed.\n",
    "5. Display and inspect postage stamps of a selected DIAObject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and Key Concepts\n",
    "\n",
    "LSST Science Pipeline code includes the ability to compare images for new or variable sources.  LSST DESC uses a package called `dia_pipe` to execute this image subtraction and analysis code.  \n",
    "In the vocabulary of LSST these are called Difference Image Analysis (DIA) products.\n",
    "* Detections on a subtracted image are called \"DIA Sources\"\n",
    "* DIA Sources are spatially associated across subtracted images into \"DIA Objects\".\n",
    "* The above two data products are made available in the `DIASource` and `DIAObject` tables.  These tables follow the definitions in the [LSST Data Products Definition Document](https://ls.st/dpdd)\n",
    "* `DIASource` and `DIAObject` tables for Run 1.2p are available through the GCR interface.  \n",
    "* The processing data repository (`repo` below) is where the processing was done.  Using the collated `DIASource` and `DIAObject` tables is much more convenient to use then loading up each of the individual files from the processing repo each time, we *will* need to use the data repository to access the image pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject gcr-catalogs that supports DIA source into path.\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.afw.display as afwDisplay\n",
    "from lsst.afw.math import Warper\n",
    "import lsst.afw.geom as afwGeom\n",
    "from lsst.daf.persistence import Butler\n",
    "from lsst.geom import SpherePoint\n",
    "import lsst.geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GCRCatalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DIA analysis is still in test phase.   The current test repo, based on Run 1.2p, is here:\n",
    "repo = '/global/cscratch1/sd/rearmstr/new_templates/diffim_template'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaSrc = GCRCatalogs.load_catalog('dc2_dia_source_run1.2p_test')\n",
    "diaObject = GCRCatalogs.load_catalog('dc2_dia_object_run1.2p_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(We presently will get a warning from the catalog reader in the initalization above because there is no u-band in the subtractions.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's star with some simple questions:\n",
    "1. How many DIA Sources are there?\n",
    "2. What's the distribution in RA, Dec?\n",
    "3. What's the mag vs. mag_err plot\n",
    "4. Can we get out the filter information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(diaSrc)} DIA Sources and {len(diaObject)} DIA Objects in this test sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_radec(cat, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax.scatter(cat['ra'], cat['dec'], marker='.')\n",
    "    ax.set_xlabel('RA')\n",
    "    ax.set_ylabel('Dec')\n",
    "    \n",
    "    # While we're doing a rectangular plot of the local tangent, we can at least get the local scale right\n",
    "    median_ra, median_dec = np.median(cat['ra']), np.median(cat['dec'])\n",
    "    ax.set_aspect(aspect=abs(1/math.cos(median_dec)))\n",
    "\n",
    "fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(8, 4))\n",
    "scatter_radec(diaSrc, ax1)\n",
    "scatter_radec(diaObject, ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hexbin_radec(cat, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax.hexbin(cat['ra'], cat['dec'])\n",
    "    # I don't know how to do colorbar from the axis\n",
    "    #    ax.colorbar()\n",
    "    ax.set_xlabel('RA')\n",
    "    ax.set_ylabel('Dec')\n",
    "\n",
    "    # While we're doing a rectangular plot of the local tangent, we can at least get the local scale right\n",
    "    median_ra, median_dec = np.median(cat['ra']), np.median(cat['dec'])\n",
    "    ax.set_aspect(aspect=abs(1/math.cos(median_dec)))\n",
    "    \n",
    "fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(8, 4))\n",
    "hexbin_radec(diaSrc, ax1)\n",
    "hexbin_radec(diaObject, ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaSrc_r = diaSrc.get_quantities(['ra', 'dec', 'mag', 'mag_err', 'psFlux', 'psFluxErr'],\n",
    "                           filters=[(lambda x: x == 'r', 'filter'), 'mag_err < 0.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hexbin_radec(diaSrc_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_mag(cat, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    mag, mag_err = cat['mag'], cat['mag_err']\n",
    "    ax.scatter(mag, mag_err, marker='.')\n",
    "    ax.set_xlabel('Mag')\n",
    "    ax.set_ylabel('Mag Err')\n",
    "\n",
    "scatter_mag(diaSrc_r)\n",
    "# Oh, there is no mag yet for diaObject.\n",
    "# scatter_mag(diaObject) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_by_filter = {}\n",
    "filter_names = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "columns = ['ra', 'dec', 'mag', 'mag_err', 'psFlux', 'psFluxErr', 'visit']\n",
    "\n",
    "for f in filter_names: \n",
    "    cat_by_filter[f] = diaSrc.get_quantities(columns,\n",
    "                                          filters=[(lambda x: x == f, 'filter'), 'mag_err < 0.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, this_cat in cat_by_filter.items():\n",
    "    plt.scatter(this_cat['mag'], this_cat['mag_err'], marker='.', label=f)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('mag')\n",
    "plt.ylabel('mag_err');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaSrc.list_all_quantities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaObject.list_all_quantities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hexbin(diaSrc['x'], diaSrc['y'])\n",
    "plt.colorbar()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.gca().set_aspect(aspect=1)\n",
    "plt.title('x, y on patch');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(diaSrc['fluxmag0']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIAObject statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(diaObject['nobs'], log=True, bins=[0, 1, 2, 5, 10, 20, 50, 100, 200])\n",
    "plt.xlabel('Number of DIA Source Observations in DIA Object')\n",
    "plt.ylabel('DIA Objects per bin');\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_chi2_r = diaObject['psFluxChi2_r']/(diaObject['psFluxNdata_r']-1)\n",
    "log10_reduced_chi2_r = np.log10(reduced_chi2_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(log10_reduced_chi2_r, range=(0, 10), bins=np.linspace(-0.25, 10.25, 21));\n",
    "plt.xlabel(r'$\\log_{10}(\\chi^2/{\\rm dof})$')\n",
    "plt.ylabel('#/bin');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(diaObject['magMean_r'], log10_reduced_chi2_r,\n",
    "           c=np.log10(diaObject['nobs']))\n",
    "\n",
    "plt.xlabel('<r> [mag]')\n",
    "plt.ylabel(r'$\\log_{10}{\\chi^2/{\\rm dof}}')\n",
    "plt.colorbar(label='log10(nobs)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(diaObject['magMean_r'], diaObject['nobs'], c=log10_reduced_chi2_r)\n",
    "plt.xlabel('<r> [mag]')\n",
    "plt.ylabel('nobs')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(diaObject['magMean_r'], diaObject['magMeanStd_r'])\n",
    "plt.xlabel('<r> [mag]')\n",
    "plt.ylabel('std(r) [mag]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Lightcurve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick an object with lots of observations and $\\chi^2/{\\rm dof}$ significantly greater than one.\n",
    "\n",
    "(Some of the `reduced_chi2` are non-positive, so we expect that we will get some \"invalid value\" warnings below when looking at the `log10_reduced_chi2` values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, = np.where((diaObject['nobs'] > 100) & (log10_reduced_chi2_r > 2) & (log10_reduced_chi2_r < 3))\n",
    "objectIds = (diaObject['diaObjectId'][w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(objectIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_diaObjectId = objectIds[0]\n",
    "this_diaObject_diaSrc = pd.DataFrame(diaSrc.get_quantities(['ra', 'dec', 'diaObjectId', 'visit', 'detector', 'filter', 'mjd', 'mag', 'mag_err', 'psFlux', 'psFluxErr'], filters=[(lambda x: x == this_diaObjectId, 'diaObjectId')]))\n",
    "this_diaObject = pd.DataFrame(diaObject.get_quantities(['ra', 'dec'], filters=[(lambda x: x == this_diaObjectId, 'diaObjectId')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_diaObject_diaSrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lightcurve(df, plot='mag', title=None, marker='o', linestyle='none', **kwargs):\n",
    "    \"\"\"Plot a lightcurve from a DataFrame.\n",
    "    \"\"\"\n",
    "    # At lexigraphical order, if not wavelength order.\n",
    "    filters = np.unique(df['filter'])\n",
    "\n",
    "    if plot == 'flux':\n",
    "        flux_col = 'psFlux'\n",
    "        flux_err_col = 'psFluxErr'\n",
    "    else:\n",
    "        flux_col = 'mag'\n",
    "        flux_err_col = 'mag_err'\n",
    "        \n",
    "    for filt in filters:\n",
    "        this_filter = df.query(f'filter == \"{filt}\"')\n",
    "        # This if sequence is a little silly.\n",
    "        if flux_err_col in this_filter.columns:\n",
    "            plt.errorbar(this_filter['mjd'], this_filter[flux_col], this_filter[flux_err_col],\n",
    "                         linestyle=linestyle, marker=marker,\n",
    "                         label=filt, **kwargs)\n",
    "        else:\n",
    "            if marker is None:\n",
    "                plt.plot(this_filter['mjd'], this_filter[flux_col],\n",
    "                         linestyle=linestyle, marker=marker,\n",
    "                         label=filt, **kwargs) \n",
    "            else:\n",
    "                plt.scatter(this_filter['mjd'], this_filter[flux_col],\n",
    "                            linestyle=linestyle, marker=marker,\n",
    "                            label=filt, **kwargs)\n",
    "\n",
    "    plt.xlabel('MJD')\n",
    "\n",
    "    if plot == 'flux':\n",
    "        plt.ylabel('psFlux [nJy]')\n",
    "    else:\n",
    "        plt.ylim(sorted(plt.ylim(), reverse=True))\n",
    "        plt.ylabel('mag [AB]')\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plot_lightcurve(this_diaObject_diaSrc, title=f'diaObjectId: {this_diaObject_diaSrc[\"diaObjectId\"][0]}')\n",
    "plt.ylim(26.5, 17);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plot_lightcurve(this_diaObject_diaSrc, plot='flux', title=f'diaObjectId: {this_diaObject_diaSrc[\"diaObjectId\"][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match to Truth Catalog\n",
    "\n",
    "This variable AGN presumably came from a variable source in the simulations.  Let's see if we can find it.  For more details on matching to the Truth Variable catalog, see\n",
    "the [GCR Truth for Variables Tutorial](https://github.com/LSSTDESC/DC2-analysis/blob/master/tutorials/truth_gcr_variables.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_cat = GCRCatalogs.load_catalog('dc2_truth_run1.2_variable_summary')\n",
    "truth_cat.list_all_quantities(include_native=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra, dec = this_diaObject['ra'][0], this_diaObject['dec'][0]\n",
    "print(ra, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_positions = SkyCoord(truth_cat['ra'], truth_cat['dec'], unit='deg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match on RA, Dec\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "ra, dec = this_diaObject['ra'][0], this_diaObject['dec'][0]\n",
    "truth = truth_cat.get_quantities(['ra', 'dec', 'uniqueId'])\n",
    "\n",
    "agn_position = SkyCoord(ra, dec, unit='deg')\n",
    "truth_positions = SkyCoord(truth['ra'], truth['dec'], unit='deg')\n",
    "\n",
    "idx, sep2d, _ = agn_position.match_to_catalog_sky(truth_positions)\n",
    "matchId = truth['uniqueId'][idx]\n",
    "\n",
    "print(f'The truth object {matchId} is {sep2d.to(u.arcsec)[0]:0.6f} away')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_match = truth_cat.get_quantities(['ra', 'dec', 'redshift', 'agn', 'uniqueId', 'sprinkled', 'galaxy_id', 'sn'],\n",
    "                                       filters=[f'uniqueId == {matchId}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the match!  Yes, it's an AGN in the truth catalog ('agn'==1)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(truth_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did we do with the lightcurve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = GCRCatalogs.load_catalog('dc2_truth_run1.2_variable_lightcurve')\n",
    "lc.list_all_quantities(include_native=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using `native_filters` for the truth lightcurve is critical to performance here\n",
    "# If you use `native_filters` then it does a match for `uniqueId` in the summary table \n",
    "# and just searches the lightcurve table for that id.\n",
    "# If you accidentally use `filters`, the GCR will search for all ids in the summary table\n",
    "# and then repeatedly search the entire lightcurve table for each ID that also matches uniqueId\n",
    "truth_lc = pd.DataFrame(lc.get_quantities(['mjd', 'mag', 'filter'],\n",
    "                                          native_filters=[f'uniqueId == {matchId}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_lc.rename(columns={'filter': 'filter_code'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_lc = truth_lc.sort_values('mjd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate filter codes to filter names\n",
    "filter_names = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "truth_lc['filter'] = [filter_names[f] for f in truth_lc['filter_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plot_lightcurve(truth_lc, plot='mag', linestyle='-', marker=None)\n",
    "plot_lightcurve(this_diaObject_diaSrc, plot='mag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postage Stamp for DIA Object\n",
    "\n",
    "For a fuller primer on making postage stamps, please see the\n",
    "[DM Butler Postage Stamp Notebook](dm_butler_postage_stamps.ipynb)\n",
    "\n",
    "But let's take a moment to discuss in more detail how the DIA products we're looking at were generated:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How these data products were generated\n",
    "\n",
    "These DIA products were generated using an existing set of Run 1.2p data that had been processed through the DM Science Pipelines.  Then `dia_pipe` was run to produce the image and individual catalog products, and code in `DC2-production` was wrun to collate these products and format them in a DPDD-like data product.\n",
    "\n",
    "`dia_pipe`\n",
    "\n",
    "* To run an image subtraction, one needs to identify a reference (or \"Template\") image.  The baseline model is that these Template images will be based on coadditions of images with the best seeing in a region.  In the DM processing these coadds are referred to as `datasetType='deepCoadd'`[1].\n",
    "\n",
    "* For each Visit, the DIA processing subtracts the Template image from the Visit image.  This resulting image and associated information (calibration, PSF, masking) is stored by the DM Butler in `datasetType='deepDiff_differenceExp'`.\n",
    "\n",
    "You will see each of these datasetTypes below when we make postage stamps.\n",
    "\n",
    "The detections on each subtracted images are called `DIASource`s and measurements on the subtracted image are stored in `datasetType='deepDiff_diaSrc'`.\n",
    "\n",
    "Once the subtractions are run on all the images, the `DIASource`s are spatially associated into `DIAObject`s.  Basic aggregrate quantities are calculated for the DIAObjects, but they're just a prototype placeholder.\n",
    "\n",
    "Here ends the code in `dia_pipe`.\n",
    "\n",
    "------\n",
    "\n",
    "`DC2-production`\n",
    "\n",
    "We then merged these `diaSrc` catalogs into a single `DIASource` table largely following the definitions laid out in the DPDD[2].  The associated catalogs were then merged into a `DIAObject` table.  Update aggregate quantities are then calculated per-filter for the `DIAObject` table.  These two tables are made available through the GCR interface.\n",
    "\n",
    "The dividing line above will move downward as the `dia_pipe` develope and eventually gets merged into the main LSST code base.\n",
    "\n",
    "Endnotes:\n",
    "[1] The discussion in this Notebook includes some specific about the current test processing done by Bob Armstrong.  Details are likely to change.  In particular the choice of template process and name will likely change.  The processing here uses the `datasetType=='deepCoadd'` to refer to a good-seeing coadd, even though that same `datasetType` could refer to the full coadd in other processing.  By 2020 this nomenclature will evolve to hopefully a less confusing place.\n",
    "\n",
    "[2] DPDD\n",
    "If you're interested in the definition of a column, learning more about the data products, or just having trouble sleeping, I encourage you to spend some quality time with \n",
    "\n",
    "[The LSST Data Products Definition Document](https://ls.st/dpdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "butler = Butler(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coadd_id_for_ra_dec(skymap, ra, dec):\n",
    "    \"\"\"\n",
    "    Return a dict suitable for use as a data ID for a DM Butler\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    skymap: lsst.afw.skyMap.SkyMap [optional] \n",
    "        Pass in to avoid the Butler read.  Useful if you have lots of such reads.\n",
    "        The skymap is just used to get the appropriate tract, patch.\n",
    "        If you want to warp to a different frame, see `wcs`.\n",
    "    ra: float\n",
    "        Right ascension of the center of the cutout, degrees\n",
    "    dec: float\n",
    "        Declination of the center of the cutout, degrees\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict  - Suitable for use as a DM Butler data ID.\n",
    "    \"\"\"   \n",
    "    # Look up the tract, patch for the RA, Dec\n",
    "    radec = SpherePoint(ra, dec, afwGeom.degrees)\n",
    "    tract_info = skymap.findTract(radec)\n",
    "    patch_info = tract_info.findPatch(radec)\n",
    "    coadd_id = {'tract': tract_info.getId(), 'patch': \"%d,%d\" % patch_info.getIndex()}\n",
    "\n",
    "    return coadd_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout_ra_dec(butler, data_id, ra, dec, dataset_type='deepDiff_differenceExp',\n",
    "                  cutout_size=75, warp_to_exposure=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Produce a cutout from dataset_type from the given butler at the given ra, dec\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Trivial wrapper around 'cutout_spherepoint'\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    butler: lsst.daf.persistence.Butler\n",
    "        Loaded DM Butler providing access to a data repository\n",
    "    data_id: Butler data ID\n",
    "        E.g., {'visit': 1181556, 'detector': 45, 'filter': 'r'}\n",
    "    ra: float\n",
    "        Right ascension of the center of the cutout, degrees\n",
    "    dec: float\n",
    "        Declination of the center of the cutout, degrees\n",
    "    cutout_size: int [optional] \n",
    "        Side of the cutout region in pixels.  Region will be cutout_size x cutout_size.\n",
    "    warp_to_exposure: optional\n",
    "        Warp coadd to system of specified 'exposure', e.g., the visit image, to warp the coadd to\n",
    "        before making the cutout.  The goal is to that a cut out of a coadd image\n",
    "        and a cutout of a visit image should line up.\n",
    "        'warp_to_exposure' overrides setting of 'cutout_size'.\n",
    "         \n",
    "    Returns\n",
    "    -------\n",
    "    MaskedImage\n",
    "    \"\"\"\n",
    "    cutout_extent = afwGeom.ExtentI(cutout_size, cutout_size)\n",
    "    radec = SpherePoint(ra, dec, afwGeom.degrees)\n",
    "   \n",
    "    image = butler.get(dataset_type, dataId=data_id)\n",
    "\n",
    "    xy = afwGeom.PointI(image.getWcs().skyToPixel(radec))\n",
    "    bbox = afwGeom.BoxI(xy - cutout_extent//2, cutout_extent)\n",
    "    \n",
    "    if warp_to_exposure is not None:\n",
    "        warper = Warper(warpingKernelName='lanczos4')\n",
    "        cutout_image = warper.warpExposure(warp_to_exposure.getWcs(), image,\n",
    "                                           destBBox=warp_to_exposure.getBBox())\n",
    "    else:\n",
    "        cutout_image = image.getCutout(radec, cutout_extent)\n",
    "    \n",
    "    return cutout_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cutout_image(butler, data_id, ra, dec,\n",
    "                      title=None,\n",
    "                      frame=None, display=None, backend='matplotlib',\n",
    "                      show=True, saveplot=False, savefits=False,\n",
    "                      zscale=None,\n",
    "                      dataset_type='deepCoadd',\n",
    "                      **kwargs):\n",
    "    \"\"\"\n",
    "    Generate and optionally display and save a postage stamp for a given RA, Dec.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    butler: lsst.daf.persistence.Butler\n",
    "        Servant providing access to a data repository\n",
    "    data_id:\n",
    "        DM Butler Data Id\n",
    "    ra: float\n",
    "        Right ascension of the center of the cutout, degrees\n",
    "    dec: float\n",
    "        Declination of the center of the cutout, degrees\n",
    "    filter: string \n",
    "        Filter of the image to load\n",
    "    Returns\n",
    "    -------\n",
    "    MaskedImage\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Uses lsst.afw.display with matplotlib to generate stamps.  Saves FITS file if requested.\n",
    "    \"\"\"\n",
    "    cutout_image = cutout_ra_dec(butler, data_id, ra, dec, dataset_type=dataset_type, **kwargs)\n",
    "    \n",
    "    if savefits:\n",
    "        if isinstance(savefits, str):\n",
    "            filename = savefits\n",
    "        else:\n",
    "            filename = 'postage-stamp.fits'\n",
    "        cutout_image.writeFits(filename)\n",
    "    \n",
    "    radec = SpherePoint(ra, dec, afwGeom.degrees)\n",
    "    xy = cutout_image.getWcs().skyToPixel(radec)\n",
    "    \n",
    "    if display is None:\n",
    "        display = afwDisplay.Display(frame=frame, backend=backend)\n",
    "\n",
    "    display.mtv(cutout_image)\n",
    "    display.scale(\"linear\", \"zscale\")\n",
    "    display.dot('o', xy.getX(), xy.getY(), ctype='red')\n",
    "    display.show_colorbar()\n",
    "\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "    if saveplot:\n",
    "        if isinstance(saveplot, str):\n",
    "            filename = saveplot\n",
    "        else:\n",
    "            filename = 'postage-stamp.png'\n",
    "        plt.savefig(filename)\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    return cutout_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra, dec = this_diaObject['ra'], this_diaObject['dec']\n",
    "print(ra, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_visit = this_diaObject_diaSrc.iloc[0]\n",
    "\n",
    "diff_id = {}\n",
    "# We have to convert from int64 to int to get the formatting to work right in the Gen 2 template string.\n",
    "diff_id['visit'] = int(diff_visit['visit'])\n",
    "diff_id['filter'] = diff_visit['filter']\n",
    "diff_id['detector'] = int(diff_visit['detector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 'deepCoadd'\n",
    "\n",
    "skymap = butler.get(\"%s_skyMap\" % dataset_type)\n",
    "coadd_id = get_coadd_id_for_ra_dec(skymap, ra, dec)\n",
    "coadd_id['filter'] = diff_id['filter']\n",
    "\n",
    "coadd_cutout = make_cutout_image(butler, coadd_id, ra, dec, dataset_type=dataset_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `make_cutout_image` is using `lsst.afw.display` to show the image.  So thus, even though the image is a cutout, it knows what the original pixel coordinates were and displays those.\n",
    "\n",
    "Also note that the orientation is in x, y of the deepCoadd image.  Because the coadds are done based on the tract+patch, x, y line up with RA, Dec.  For our science image cutouts that we'll see below we will choose to use the `warp_to_exposure` option to map each science and subtracted image to these same coordinates to make comparisons easy.  Note that in the actually processing, the subtraction was in fact done by warping the coadd to the science image, but showing each image in its own orientation will make it much harder to understand the stamps.\n",
    "\n",
    "The above image is in fact gray scale.  It looks blue, because the \"footprint\" of the galaxy, i.e. all of the pixels associated with the measurement of the galaxy, covers the entire postage stamp region, and by default we are displaying the mask planes. A 'mask' doesn't mean good or bad, it's a plane of information about a particular property.  While many mask bits refer to problems, or potential problems, one of the key mask bits is DETECTED, which defines the footprint of the object. \n",
    "\n",
    "We can look up what those mask planes are but creating just a dummy display and asking what the mask plane bits are for our image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 1\n",
    "plt.figure(frame)\n",
    "display = afwDisplay.Display(frame=frame, backend='matplotlib', title='coadd')\n",
    "\n",
    "for maskName, maskBit in coadd_cutout.mask.getMaskPlaneDict().items():\n",
    "    print('{}: {}'.format(maskName, display.getMaskPlaneColor(maskName)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can see that `DETECTED` is blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_cutout = make_cutout_image(butler, diff_id, ra, dec, dataset_type='calexp',\n",
    "                                   warp_to_exposure=coadd_cutout, title='science image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the mask plane is displaying all pixels that are part of footprints of something.  Thus it is showing more than just the specific footprint of the object we're centered on.\n",
    "\n",
    "Note that the pixel coordinates for this postage stamp are those of the *coadd* image because that's what we warped to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_image = make_cutout_image(butler, diff_id, ra, dec, dataset_type='deepDiff_differenceExp',\n",
    "                                 warp_to_exposure=coadd_cutout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The detected `diaSource` footprint is in blue.\n",
    "\n",
    "You also might notice a significant green stripe going up and to the left.  This (I believe) are interpolated pixels `INTRP`, where the interpolation contamination has been convolved out to a very large area by the effective size of the convoultion kernel.  The threshold for determining when a pixel is affeted by a given mask plane bit as its grown out like this is configurable.\n",
    "\n",
    "Somewhat confusingly, `DETECTED_NEGATIVE` is also green.  You'll see some examples of negative detections below in the postage stamps of the difference images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(this_diaObject_diaSrc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A given science+difference image pair is oriented the same way, because the coadd is matched to the orientation of the science image.  But because each visit is oriented differently, each postage stamp below will be oriented differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Catch attempts to make stamps to near the edge of the image to complete.\n",
    "# There are diaSources smaller than this.\n",
    "# Our choice of cutout size is slightly arbitrary and is also much larger than a point source.\n",
    "# An improvement would be to get the postage stamp to return a full image with the mask plane set appropriately \n",
    "# for the missing pixels.\n",
    "\n",
    "from lsst.pex.exceptions import LengthError\n",
    "\n",
    "for diff_visit in this_diaObject_diaSrc.itertuples():\n",
    "    diff_id = {}\n",
    "    # We have to convert from int64 to int to get the formatting to work right in the Gen 2 template string.\n",
    "    diff_id['visit'] = int(diff_visit.visit)\n",
    "    diff_id['filter'] = diff_visit.filter\n",
    "    diff_id['detector'] = int(diff_visit.detector)\n",
    "    title = f'''diaObjectId: {diff_visit.diaObjectId}  MJD: {diff_visit.mjd}\n",
    "        visit: {diff_visit.visit} filter: {diff_visit.filter} detector: {diff_visit.detector}'''\n",
    "    mjd = diff_visit.mjd\n",
    "    diaObjectId = diff_visit.diaObjectId\n",
    "    \n",
    "    try:\n",
    "        make_cutout_image(butler, diff_id, ra, dec, dataset_type='deepDiff_differenceExp', \n",
    "                          warp_to_exposure=coadd_cutout, title=title)\n",
    "    except LengthError:\n",
    "        print('Too near edge of image to get full postage stamp.  Skipping {dataId}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-stack",
   "language": "python",
   "name": "desc-stack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
